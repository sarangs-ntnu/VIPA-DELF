{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a355f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from vit_pytorch import ViT\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2890be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_dir=\"./../processed_RealDS/train\"\n",
    "val_root_dir=\"./../processed_RealDS/validation\"\n",
    "test_root_dir=\"./../processed_RealDS/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc656724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f2f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Training\n",
    "####################################\n",
    "\n",
    "trans={\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4762, 0.3054, 0.2368],\n",
    "                             [0.3345, 0.2407, 0.2164])\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'valid':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4762, 0.3054, 0.2368],\n",
    "                             [0.3345, 0.2407, 0.2164])\n",
    "    ]),\n",
    "    \n",
    "    # Test does not use augmentation\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4762, 0.3054, 0.2368],\n",
    "                             [0.3345, 0.2407, 0.2164])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426ee994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training set images:1600\n",
      "Number of Validation set images:19\n",
      "Number of Test set images:30\n"
     ]
    }
   ],
   "source": [
    "#Generators\n",
    "training_dataset = ImageFolder(train_root_dir,transform=trans['train'])\n",
    "validation_dataset = ImageFolder(val_root_dir,transform=trans['valid'])\n",
    "test_dataset = ImageFolder(test_root_dir,transform=trans['test'])\n",
    "\n",
    "train_dataloader = DataLoader(training_dataset,batch_size,shuffle=True) # ** unpacks a dictionary into keyword arguments\n",
    "val_dataloader = DataLoader(validation_dataset,batch_size)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size)\n",
    "\n",
    "print('Number of Training set images:{}'.format(len(training_dataset)))\n",
    "print('Number of Validation set images:{}'.format(len(validation_dataset)))\n",
    "print('Number of Test set images:{}'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2748a2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (to_patch_embedding): Sequential(\n",
       "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=32, p2=32)\n",
       "    (1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (transformer): Transformer(\n",
       "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x ModuleList(\n",
       "        (0): Attention(\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attend): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (5): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Vision Transformer model\n",
    "model = ViT(\n",
    "    image_size=224,\n",
    "    patch_size=32,\n",
    "    num_classes=len(training_dataset.classes),\n",
    "    dim=768,  # Dimension of the model\n",
    "    depth=12,  # Number of transformer layers\n",
    "    heads=12,  # Number of attention heads\n",
    "    mlp_dim=3072,  # Dimension of the MLP layers\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Set the device to use (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(\"Device: \", device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24600943",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f95172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/35: 100%|██████████| 50/50 [00:17<00:00,  2.86batch/s, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 1/35, Loss: 0.6725830394029617\n",
      "Validation - Epoch 1/35, Loss: 0.43615612387657166\n",
      "Validation - Epoch 1/35, Accuracy: 84.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/35: 100%|██████████| 50/50 [00:14<00:00,  3.47batch/s, loss=0.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 2/35, Loss: 0.3458257269859314\n",
      "Validation - Epoch 2/35, Loss: 0.5094606280326843\n",
      "Validation - Epoch 2/35, Accuracy: 78.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/35: 100%|██████████| 50/50 [00:14<00:00,  3.51batch/s, loss=0.303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 3/35, Loss: 0.30270934030413627\n",
      "Validation - Epoch 3/35, Loss: 0.4410644769668579\n",
      "Validation - Epoch 3/35, Accuracy: 84.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/35: 100%|██████████| 50/50 [00:14<00:00,  3.38batch/s, loss=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 4/35, Loss: 0.19477710239589213\n",
      "Validation - Epoch 4/35, Loss: 0.259253591299057\n",
      "Validation - Epoch 4/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/35: 100%|██████████| 50/50 [00:14<00:00,  3.46batch/s, loss=0.106] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 5/35, Loss: 0.1063788290321827\n",
      "Validation - Epoch 5/35, Loss: 0.3562778830528259\n",
      "Validation - Epoch 5/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/35: 100%|██████████| 50/50 [00:14<00:00,  3.47batch/s, loss=0.098] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 6/35, Loss: 0.0980429395288229\n",
      "Validation - Epoch 6/35, Loss: 0.31843802332878113\n",
      "Validation - Epoch 6/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/35: 100%|██████████| 50/50 [00:14<00:00,  3.44batch/s, loss=0.0809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 7/35, Loss: 0.08085588354617357\n",
      "Validation - Epoch 7/35, Loss: 0.35794970393180847\n",
      "Validation - Epoch 7/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/35: 100%|██████████| 50/50 [00:14<00:00,  3.45batch/s, loss=0.0646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 8/35, Loss: 0.06461690817959606\n",
      "Validation - Epoch 8/35, Loss: 0.3275861144065857\n",
      "Validation - Epoch 8/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/35: 100%|██████████| 50/50 [00:14<00:00,  3.50batch/s, loss=0.056] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 9/35, Loss: 0.055961893247440456\n",
      "Validation - Epoch 9/35, Loss: 0.20932935178279877\n",
      "Validation - Epoch 9/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/35: 100%|██████████| 50/50 [00:14<00:00,  3.50batch/s, loss=0.0632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 10/35, Loss: 0.06315691477619112\n",
      "Validation - Epoch 10/35, Loss: 0.381751149892807\n",
      "Validation - Epoch 10/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/35: 100%|██████████| 50/50 [00:14<00:00,  3.38batch/s, loss=0.0514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 11/35, Loss: 0.05142363966908306\n",
      "Validation - Epoch 11/35, Loss: 0.4255070388317108\n",
      "Validation - Epoch 11/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/35: 100%|██████████| 50/50 [00:14<00:00,  3.48batch/s, loss=0.0646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 12/35, Loss: 0.06457997617311775\n",
      "Validation - Epoch 12/35, Loss: 0.3588961064815521\n",
      "Validation - Epoch 12/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/35: 100%|██████████| 50/50 [00:14<00:00,  3.45batch/s, loss=0.0369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 13/35, Loss: 0.03692597491433844\n",
      "Validation - Epoch 13/35, Loss: 0.4226158559322357\n",
      "Validation - Epoch 13/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/35: 100%|██████████| 50/50 [00:14<00:00,  3.36batch/s, loss=0.0307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 14/35, Loss: 0.03066473395563662\n",
      "Validation - Epoch 14/35, Loss: 0.4326937198638916\n",
      "Validation - Epoch 14/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/35: 100%|██████████| 50/50 [00:14<00:00,  3.41batch/s, loss=0.0405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 15/35, Loss: 0.04054987074574456\n",
      "Validation - Epoch 15/35, Loss: 0.34798556566238403\n",
      "Validation - Epoch 15/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/35: 100%|██████████| 50/50 [00:14<00:00,  3.42batch/s, loss=0.0359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 16/35, Loss: 0.03587321045808494\n",
      "Validation - Epoch 16/35, Loss: 0.32558953762054443\n",
      "Validation - Epoch 16/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/35: 100%|██████████| 50/50 [00:13<00:00,  3.60batch/s, loss=0.0377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 17/35, Loss: 0.03773732263827696\n",
      "Validation - Epoch 17/35, Loss: 0.30029869079589844\n",
      "Validation - Epoch 17/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/35: 100%|██████████| 50/50 [00:13<00:00,  3.59batch/s, loss=0.0356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 18/35, Loss: 0.03557224759424571\n",
      "Validation - Epoch 18/35, Loss: 0.35753005743026733\n",
      "Validation - Epoch 18/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/35: 100%|██████████| 50/50 [00:14<00:00,  3.52batch/s, loss=0.0545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 19/35, Loss: 0.05447992542642169\n",
      "Validation - Epoch 19/35, Loss: 0.3151153326034546\n",
      "Validation - Epoch 19/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/35: 100%|██████████| 50/50 [00:14<00:00,  3.46batch/s, loss=0.0377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 20/35, Loss: 0.037735212070983834\n",
      "Validation - Epoch 20/35, Loss: 0.34606868028640747\n",
      "Validation - Epoch 20/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/35: 100%|██████████| 50/50 [00:14<00:00,  3.44batch/s, loss=0.03]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 21/35, Loss: 0.029960242436500265\n",
      "Validation - Epoch 21/35, Loss: 0.423836350440979\n",
      "Validation - Epoch 21/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/35: 100%|██████████| 50/50 [00:14<00:00,  3.40batch/s, loss=0.0271] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 22/35, Loss: 0.027087427609367297\n",
      "Validation - Epoch 22/35, Loss: 0.33514222502708435\n",
      "Validation - Epoch 22/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/35: 100%|██████████| 50/50 [00:14<00:00,  3.43batch/s, loss=0.0234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 23/35, Loss: 0.02344280424527824\n",
      "Validation - Epoch 23/35, Loss: 0.2992278039455414\n",
      "Validation - Epoch 23/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/35: 100%|██████████| 50/50 [00:14<00:00,  3.46batch/s, loss=0.0211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 24/35, Loss: 0.021055261041910852\n",
      "Validation - Epoch 24/35, Loss: 0.34855756163597107\n",
      "Validation - Epoch 24/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/35: 100%|██████████| 50/50 [00:14<00:00,  3.51batch/s, loss=0.0438] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 25/35, Loss: 0.04382841961865779\n",
      "Validation - Epoch 25/35, Loss: 0.24392656981945038\n",
      "Validation - Epoch 25/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/35: 100%|██████████| 50/50 [00:14<00:00,  3.35batch/s, loss=0.027] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 26/35, Loss: 0.02696623102063313\n",
      "Validation - Epoch 26/35, Loss: 0.43590033054351807\n",
      "Validation - Epoch 26/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/35: 100%|██████████| 50/50 [00:14<00:00,  3.43batch/s, loss=0.0243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 27/35, Loss: 0.024306852975860237\n",
      "Validation - Epoch 27/35, Loss: 0.28790900111198425\n",
      "Validation - Epoch 27/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/35: 100%|██████████| 50/50 [00:14<00:00,  3.46batch/s, loss=0.0223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 28/35, Loss: 0.022282992944237776\n",
      "Validation - Epoch 28/35, Loss: 0.42373165488243103\n",
      "Validation - Epoch 28/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/35: 100%|██████████| 50/50 [00:14<00:00,  3.35batch/s, loss=0.0173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 29/35, Loss: 0.017262013048748484\n",
      "Validation - Epoch 29/35, Loss: 0.3167019784450531\n",
      "Validation - Epoch 29/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/35: 100%|██████████| 50/50 [00:14<00:00,  3.42batch/s, loss=0.0268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 30/35, Loss: 0.02675908955250634\n",
      "Validation - Epoch 30/35, Loss: 0.29010382294654846\n",
      "Validation - Epoch 30/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/35: 100%|██████████| 50/50 [00:14<00:00,  3.49batch/s, loss=0.0312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 31/35, Loss: 0.031233067314169603\n",
      "Validation - Epoch 31/35, Loss: 0.3330632448196411\n",
      "Validation - Epoch 31/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/35: 100%|██████████| 50/50 [00:14<00:00,  3.42batch/s, loss=0.0139] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 32/35, Loss: 0.013896803817842737\n",
      "Validation - Epoch 32/35, Loss: 0.4039005935192108\n",
      "Validation - Epoch 32/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/35: 100%|██████████| 50/50 [00:14<00:00,  3.36batch/s, loss=0.0117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 33/35, Loss: 0.011742404209398956\n",
      "Validation - Epoch 33/35, Loss: 0.42254528403282166\n",
      "Validation - Epoch 33/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/35: 100%|██████████| 50/50 [00:14<00:00,  3.46batch/s, loss=0.0257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 34/35, Loss: 0.025715493727911962\n",
      "Validation - Epoch 34/35, Loss: 0.44618356227874756\n",
      "Validation - Epoch 34/35, Accuracy: 89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/35: 100%|██████████| 50/50 [00:14<00:00,  3.54batch/s, loss=0.0287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 35/35, Loss: 0.028678646354237572\n",
      "Validation - Epoch 35/35, Loss: 0.34118860960006714\n",
      "Validation - Epoch 35/35, Accuracy: 89.47%\n",
      "Training completed and modal saved to vit_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Use tqdm for a progress bar\n",
    "    with tqdm(total=len(train_dataloader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            pbar.set_postfix(loss=running_loss / (i + 1))\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_dataloader)}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    print(f'Validation - Epoch {epoch+1}/{num_epochs}, Loss: {val_loss/len(val_dataloader)}')\n",
    "\n",
    "    # Compute and print validation accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    print(f'Validation - Epoch {epoch+1}/{num_epochs}, Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'vit_model.pth')\n",
    "print(\"Training completed and modal saved to vit_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe209e",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d5e63",
   "metadata": {},
   "source": [
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee5e9812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 16))\n",
    "# sns.set(font_scale=1.5)\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc307d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
