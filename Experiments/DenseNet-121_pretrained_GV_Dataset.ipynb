{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbe063d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from Validate import validate_net\n",
    "from Test import test_net\n",
    "from misc import print_metrics, training_curve \n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import logging\n",
    "import csv\n",
    "from torchvision import transforms, datasets, models\n",
    "import sklearn.metrics as mtc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7f6e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "# Checking if GPU is used\n",
    "###########################\n",
    "\n",
    "use_cuda=torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "device=torch.device(\"cuda:0\" if use_cuda else \"mps\" if use_mps else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc82d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Setting basic parameters for the model\n",
    "########################################           \n",
    "         \n",
    "batch_size=32\n",
    "max_epochs=30\n",
    "lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76bada85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of dataset\n",
    "dir_original = \"./../GrapevineDS\"\n",
    "\n",
    "# name of new dataset\n",
    "dir_processed = \"./../data_processed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b121c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_samples:  ['train', 'validation', 'test'] \n",
      "\n",
      "class:  ['esca' 'healthy'] \n",
      "\n",
      "number of images for class:  [888 882] \n",
      "\n",
      "split of dataset: \n",
      "  [[533 133 222]\n",
      " [529 132 220]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(dir_original)\n",
    "\n",
    "set_samples = ['train', 'validation', 'test']\n",
    "print(\"set_samples: \", set_samples, \"\\n\")\n",
    "\n",
    "CLASS_NAMES = np.array([item.name for item in sorted(data_dir.glob('*'))])\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "print(\"class: \", CLASS_NAMES, \"\\n\")\n",
    "\n",
    "N_IMAGES = np.array([len(list(data_dir.glob(item.name+'/*.jpg'))) for item in sorted(data_dir.glob('*'))])\t\t\t# number of images for class\n",
    "print(\"number of images for class: \", N_IMAGES, \"\\n\")\n",
    "\n",
    "N_samples = np.array([(int(np.around(n*60/100)), int(np.around(n*15/100)), int(np.around(n*25/100))) for n in N_IMAGES])\t# number of images for set (train,validation,test)\n",
    "print(\"split of dataset: \\n \", N_samples, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bbedb5",
   "metadata": {},
   "source": [
    "### Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a19d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of new images\n",
    "# size of new images\n",
    "size = 1280, 720\n",
    "\n",
    "# Create the new dataset\n",
    "# Split Dataset (also resize and rotate)\n",
    "\n",
    "try:\n",
    "    # Check if dir_processed exists and is a directory\n",
    "    if not os.path.isdir(dir_processed):\n",
    "        # If it's not a directory, create it\n",
    "        os.makedirs(dir_processed)\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "\n",
    "# Now create subdirectories for sets and classes\n",
    "for set_tag in set_samples:\n",
    "    os.makedirs(os.path.join(dir_processed, set_tag),exist_ok=True)\n",
    "    for class_name in CLASS_NAMES:\n",
    "        os.makedirs(os.path.join(dir_processed, set_tag, class_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9987dea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split dataset.\n",
      "class name:  esca\n",
      "image:  0\n",
      "image:  1\n",
      "image:  2\n",
      "image:  3\n",
      "image:  4\n",
      "image:  5\n",
      "image:  6\n",
      "image:  7\n",
      "image:  8\n",
      "image:  9\n",
      "image:  10\n",
      "image:  11\n",
      "image:  12\n",
      "image:  13\n",
      "image:  14\n",
      "image:  15\n",
      "image:  16\n",
      "image:  17\n",
      "image:  18\n",
      "image:  19\n",
      "image:  20\n",
      "image:  21\n",
      "image:  22\n",
      "image:  23\n",
      "image:  24\n",
      "image:  25\n",
      "image:  26\n",
      "image:  27\n",
      "image:  28\n",
      "image:  29\n",
      "image:  30\n",
      "image:  31\n",
      "image:  32\n",
      "image:  33\n",
      "image:  34\n",
      "image:  35\n",
      "image:  36\n",
      "image:  37\n",
      "image:  38\n",
      "image:  39\n",
      "image:  40\n",
      "image:  41\n",
      "image:  42\n",
      "image:  43\n",
      "image:  44\n",
      "image:  45\n",
      "image:  46\n",
      "image:  47\n",
      "image:  48\n",
      "image:  49\n",
      "image:  50\n",
      "image:  51\n",
      "image:  52\n",
      "image:  53\n",
      "image:  54\n",
      "image:  55\n",
      "image:  56\n",
      "image:  57\n",
      "image:  58\n",
      "image:  59\n",
      "image:  60\n",
      "image:  61\n",
      "image:  62\n",
      "image:  63\n",
      "image:  64\n",
      "image:  65\n",
      "image:  66\n",
      "image:  67\n",
      "image:  68\n",
      "image:  69\n",
      "image:  70\n",
      "image:  71\n",
      "image:  72\n",
      "image:  73\n",
      "image:  74\n",
      "image:  75\n",
      "image:  76\n",
      "image:  77\n",
      "image:  78\n",
      "image:  79\n",
      "image:  80\n",
      "image:  81\n",
      "image:  82\n",
      "image:  83\n",
      "image:  84\n",
      "image:  85\n",
      "image:  86\n",
      "image:  87\n",
      "image:  88\n",
      "image:  89\n",
      "image:  90\n",
      "image:  91\n",
      "image:  92\n",
      "image:  93\n",
      "image:  94\n",
      "image:  95\n",
      "image:  96\n",
      "image:  97\n",
      "image:  98\n",
      "image:  99\n",
      "image:  100\n",
      "image:  101\n",
      "image:  102\n",
      "image:  103\n",
      "image:  104\n",
      "image:  105\n",
      "image:  106\n",
      "image:  107\n",
      "image:  108\n",
      "image:  109\n",
      "image:  110\n",
      "image:  111\n",
      "image:  112\n",
      "image:  113\n",
      "image:  114\n",
      "image:  115\n",
      "image:  116\n",
      "image:  117\n",
      "image:  118\n",
      "image:  119\n",
      "image:  120\n",
      "image:  121\n",
      "image:  122\n",
      "image:  123\n",
      "image:  124\n",
      "image:  125\n",
      "image:  126\n",
      "image:  127\n",
      "image:  128\n",
      "image:  129\n",
      "image:  130\n",
      "image:  131\n",
      "image:  132\n",
      "image:  133\n",
      "image:  134\n",
      "image:  135\n",
      "image:  136\n",
      "image:  137\n",
      "image:  138\n",
      "image:  139\n",
      "image:  140\n",
      "image:  141\n",
      "image:  142\n",
      "image:  143\n",
      "image:  144\n",
      "image:  145\n",
      "image:  146\n",
      "image:  147\n",
      "image:  148\n",
      "image:  149\n",
      "image:  150\n",
      "image:  151\n",
      "image:  152\n",
      "image:  153\n",
      "image:  154\n",
      "image:  155\n",
      "image:  156\n",
      "image:  157\n",
      "image:  158\n",
      "image:  159\n",
      "image:  160\n",
      "image:  161\n",
      "image:  162\n",
      "image:  163\n",
      "image:  164\n",
      "image:  165\n",
      "image:  166\n",
      "image:  167\n",
      "image:  168\n",
      "image:  169\n",
      "image:  170\n",
      "image:  171\n",
      "image:  172\n",
      "image:  173\n",
      "image:  174\n",
      "image:  175\n",
      "image:  176\n",
      "image:  177\n",
      "image:  178\n",
      "image:  179\n",
      "image:  180\n",
      "image:  181\n",
      "image:  182\n",
      "image:  183\n",
      "image:  184\n",
      "image:  185\n",
      "image:  186\n",
      "image:  187\n",
      "image:  188\n",
      "image:  189\n",
      "image:  190\n",
      "image:  191\n",
      "image:  192\n",
      "image:  193\n",
      "image:  194\n",
      "image:  195\n",
      "image:  196\n",
      "image:  197\n",
      "image:  198\n",
      "image:  199\n",
      "image:  200\n",
      "image:  201\n",
      "image:  202\n",
      "image:  203\n",
      "image:  204\n",
      "image:  205\n",
      "image:  206\n",
      "image:  207\n",
      "image:  208\n",
      "image:  209\n",
      "image:  210\n",
      "image:  211\n",
      "image:  212\n",
      "image:  213\n",
      "image:  214\n",
      "image:  215\n",
      "image:  216\n",
      "image:  217\n",
      "image:  218\n",
      "image:  219\n",
      "image:  220\n",
      "image:  221\n",
      "image:  222\n",
      "image:  223\n",
      "image:  224\n",
      "image:  225\n",
      "image:  226\n",
      "image:  227\n",
      "image:  228\n",
      "image:  229\n",
      "image:  230\n",
      "image:  231\n",
      "image:  232\n",
      "image:  233\n",
      "image:  234\n",
      "image:  235\n",
      "image:  236\n",
      "image:  237\n",
      "image:  238\n",
      "image:  239\n",
      "image:  240\n",
      "image:  241\n",
      "image:  242\n",
      "image:  243\n",
      "image:  244\n",
      "image:  245\n",
      "image:  246\n",
      "image:  247\n",
      "image:  248\n",
      "image:  249\n",
      "image:  250\n",
      "image:  251\n",
      "image:  252\n",
      "image:  253\n",
      "image:  254\n",
      "image:  255\n",
      "image:  256\n",
      "image:  257\n",
      "image:  258\n",
      "image:  259\n",
      "image:  260\n",
      "image:  261\n",
      "image:  262\n",
      "image:  263\n",
      "image:  264\n",
      "image:  265\n",
      "image:  266\n",
      "image:  267\n",
      "image:  268\n",
      "image:  269\n",
      "image:  270\n",
      "image:  271\n",
      "image:  272\n",
      "image:  273\n",
      "image:  274\n",
      "image:  275\n",
      "image:  276\n",
      "image:  277\n",
      "image:  278\n",
      "image:  279\n",
      "image:  280\n",
      "image:  281\n",
      "image:  282\n",
      "image:  283\n",
      "image:  284\n",
      "image:  285\n",
      "image:  286\n",
      "image:  287\n",
      "image:  288\n",
      "image:  289\n",
      "image:  290\n",
      "image:  291\n",
      "image:  292\n",
      "image:  293\n",
      "image:  294\n",
      "image:  295\n",
      "image:  296\n",
      "image:  297\n",
      "image:  298\n",
      "image:  299\n",
      "image:  300\n",
      "image:  301\n",
      "image:  302\n",
      "image:  303\n",
      "image:  304\n",
      "image:  305\n",
      "image:  306\n",
      "image:  307\n",
      "image:  308\n",
      "image:  309\n",
      "image:  310\n",
      "image:  311\n",
      "image:  312\n",
      "image:  313\n",
      "image:  314\n",
      "image:  315\n",
      "image:  316\n",
      "image:  317\n",
      "image:  318\n",
      "image:  319\n",
      "image:  320\n",
      "image:  321\n",
      "image:  322\n",
      "image:  323\n",
      "image:  324\n",
      "image:  325\n",
      "image:  326\n",
      "image:  327\n",
      "image:  328\n",
      "image:  329\n",
      "image:  330\n",
      "image:  331\n",
      "image:  332\n",
      "image:  333\n",
      "image:  334\n",
      "image:  335\n",
      "image:  336\n",
      "image:  337\n",
      "image:  338\n",
      "image:  339\n",
      "image:  340\n",
      "image:  341\n",
      "image:  342\n",
      "image:  343\n",
      "image:  344\n",
      "image:  345\n",
      "image:  346\n",
      "image:  347\n",
      "image:  348\n",
      "image:  349\n",
      "image:  350\n",
      "image:  351\n",
      "image:  352\n",
      "image:  353\n",
      "image:  354\n",
      "image:  355\n",
      "image:  356\n",
      "image:  357\n",
      "image:  358\n",
      "image:  359\n",
      "image:  360\n",
      "image:  361\n",
      "image:  362\n",
      "image:  363\n",
      "image:  364\n",
      "image:  365\n",
      "image:  366\n",
      "image:  367\n",
      "image:  368\n",
      "image:  369\n",
      "image:  370\n",
      "image:  371\n",
      "image:  372\n",
      "image:  373\n",
      "image:  374\n",
      "image:  375\n",
      "image:  376\n",
      "image:  377\n",
      "image:  378\n",
      "image:  379\n",
      "image:  380\n",
      "image:  381\n",
      "image:  382\n",
      "image:  383\n",
      "image:  384\n",
      "image:  385\n",
      "image:  386\n",
      "image:  387\n",
      "image:  388\n",
      "image:  389\n",
      "image:  390\n",
      "image:  391\n",
      "image:  392\n",
      "image:  393\n",
      "image:  394\n",
      "image:  395\n",
      "image:  396\n",
      "image:  397\n",
      "image:  398\n",
      "image:  399\n",
      "image:  400\n",
      "image:  401\n",
      "image:  402\n",
      "image:  403\n",
      "image:  404\n",
      "image:  405\n",
      "image:  406\n",
      "image:  407\n",
      "image:  408\n",
      "image:  409\n",
      "image:  410\n",
      "image:  411\n",
      "image:  412\n",
      "image:  413\n",
      "image:  414\n",
      "image:  415\n",
      "image:  416\n",
      "image:  417\n",
      "image:  418\n",
      "image:  419\n",
      "image:  420\n",
      "image:  421\n",
      "image:  422\n",
      "image:  423\n",
      "image:  424\n",
      "image:  425\n",
      "image:  426\n",
      "image:  427\n",
      "image:  428\n",
      "image:  429\n",
      "image:  430\n",
      "image:  431\n",
      "image:  432\n",
      "image:  433\n",
      "image:  434\n",
      "image:  435\n",
      "image:  436\n",
      "image:  437\n",
      "image:  438\n",
      "image:  439\n",
      "image:  440\n",
      "image:  441\n",
      "image:  442\n",
      "image:  443\n",
      "image:  444\n",
      "image:  445\n",
      "image:  446\n",
      "image:  447\n",
      "image:  448\n",
      "image:  449\n",
      "image:  450\n",
      "image:  451\n",
      "image:  452\n",
      "image:  453\n",
      "image:  454\n",
      "image:  455\n",
      "image:  456\n",
      "image:  457\n",
      "image:  458\n",
      "image:  459\n",
      "image:  460\n",
      "image:  461\n",
      "image:  462\n",
      "image:  463\n",
      "image:  464\n",
      "image:  465\n",
      "image:  466\n",
      "image:  467\n",
      "image:  468\n",
      "image:  469\n",
      "image:  470\n",
      "image:  471\n",
      "image:  472\n",
      "image:  473\n",
      "image:  474\n",
      "image:  475\n",
      "image:  476\n",
      "image:  477\n",
      "image:  478\n",
      "image:  479\n",
      "image:  480\n",
      "image:  481\n",
      "image:  482\n",
      "image:  483\n",
      "image:  484\n",
      "image:  485\n",
      "image:  486\n",
      "image:  487\n",
      "image:  488\n",
      "image:  489\n",
      "image:  490\n",
      "image:  491\n",
      "image:  492\n",
      "image:  493\n",
      "image:  494\n",
      "image:  495\n",
      "image:  496\n",
      "image:  497\n",
      "image:  498\n",
      "image:  499\n",
      "image:  500\n",
      "image:  501\n",
      "image:  502\n",
      "image:  503\n",
      "image:  504\n",
      "image:  505\n",
      "image:  506\n",
      "image:  507\n",
      "image:  508\n",
      "image:  509\n",
      "image:  510\n",
      "image:  511\n",
      "image:  512\n",
      "image:  513\n",
      "image:  514\n",
      "image:  515\n",
      "image:  516\n",
      "image:  517\n",
      "image:  518\n",
      "image:  519\n",
      "image:  520\n",
      "image:  521\n",
      "image:  522\n",
      "image:  523\n",
      "image:  524\n",
      "image:  525\n",
      "image:  526\n",
      "image:  527\n",
      "image:  528\n",
      "image:  529\n",
      "image:  530\n",
      "image:  531\n",
      "image:  532\n",
      "image:  533\n",
      "updating k:  0\n",
      "3\n",
      "image:  534\n",
      "image:  535\n",
      "image:  536\n",
      "image:  537\n",
      "image:  538\n",
      "image:  539\n",
      "image:  540\n",
      "image:  541\n",
      "image:  542\n",
      "image:  543\n",
      "image:  544\n",
      "image:  545\n",
      "image:  546\n",
      "image:  547\n",
      "image:  548\n",
      "image:  549\n",
      "image:  550\n",
      "image:  551\n",
      "image:  552\n",
      "image:  553\n",
      "image:  554\n",
      "image:  555\n",
      "image:  556\n",
      "image:  557\n",
      "image:  558\n",
      "image:  559\n",
      "image:  560\n",
      "image:  561\n",
      "image:  562\n",
      "image:  563\n",
      "image:  564\n",
      "image:  565\n",
      "image:  566\n",
      "image:  567\n",
      "image:  568\n",
      "image:  569\n",
      "image:  570\n",
      "image:  571\n",
      "image:  572\n",
      "image:  573\n",
      "image:  574\n",
      "image:  575\n",
      "image:  576\n",
      "image:  577\n",
      "image:  578\n",
      "image:  579\n",
      "image:  580\n",
      "image:  581\n",
      "image:  582\n",
      "image:  583\n",
      "image:  584\n",
      "image:  585\n",
      "image:  586\n",
      "image:  587\n",
      "image:  588\n",
      "image:  589\n",
      "image:  590\n",
      "image:  591\n",
      "image:  592\n",
      "image:  593\n",
      "image:  594\n",
      "image:  595\n",
      "image:  596\n",
      "image:  597\n",
      "image:  598\n",
      "image:  599\n",
      "image:  600\n",
      "image:  601\n",
      "image:  602\n",
      "image:  603\n",
      "image:  604\n",
      "image:  605\n",
      "image:  606\n",
      "image:  607\n",
      "image:  608\n",
      "image:  609\n",
      "image:  610\n",
      "image:  611\n",
      "image:  612\n",
      "image:  613\n",
      "image:  614\n",
      "image:  615\n",
      "image:  616\n",
      "image:  617\n",
      "image:  618\n",
      "image:  619\n",
      "image:  620\n",
      "image:  621\n",
      "image:  622\n",
      "image:  623\n",
      "image:  624\n",
      "image:  625\n",
      "image:  626\n",
      "image:  627\n",
      "image:  628\n",
      "image:  629\n",
      "image:  630\n",
      "image:  631\n",
      "image:  632\n",
      "image:  633\n",
      "image:  634\n",
      "image:  635\n",
      "image:  636\n",
      "image:  637\n",
      "image:  638\n",
      "image:  639\n",
      "image:  640\n",
      "image:  641\n",
      "image:  642\n",
      "image:  643\n",
      "image:  644\n",
      "image:  645\n",
      "image:  646\n",
      "image:  647\n",
      "image:  648\n",
      "image:  649\n",
      "image:  650\n",
      "image:  651\n",
      "image:  652\n",
      "image:  653\n",
      "image:  654\n",
      "image:  655\n",
      "image:  656\n",
      "image:  657\n",
      "image:  658\n",
      "image:  659\n",
      "image:  660\n",
      "image:  661\n",
      "image:  662\n",
      "image:  663\n",
      "image:  664\n",
      "image:  665\n",
      "image:  666\n",
      "updating k:  1\n",
      "3\n",
      "image:  667\n",
      "image:  668\n",
      "image:  669\n",
      "image:  670\n",
      "image:  671\n",
      "image:  672\n",
      "image:  673\n",
      "image:  674\n",
      "image:  675\n",
      "image:  676\n",
      "image:  677\n",
      "image:  678\n",
      "image:  679\n",
      "image:  680\n",
      "image:  681\n",
      "image:  682\n",
      "image:  683\n",
      "image:  684\n",
      "image:  685\n",
      "image:  686\n",
      "image:  687\n",
      "image:  688\n",
      "image:  689\n",
      "image:  690\n",
      "image:  691\n",
      "image:  692\n",
      "image:  693\n",
      "image:  694\n",
      "image:  695\n",
      "image:  696\n",
      "image:  697\n",
      "image:  698\n",
      "image:  699\n",
      "image:  700\n",
      "image:  701\n",
      "image:  702\n",
      "image:  703\n",
      "image:  704\n",
      "image:  705\n",
      "image:  706\n",
      "image:  707\n",
      "image:  708\n",
      "image:  709\n",
      "image:  710\n",
      "image:  711\n",
      "image:  712\n",
      "image:  713\n",
      "image:  714\n",
      "image:  715\n",
      "image:  716\n",
      "image:  717\n",
      "image:  718\n",
      "image:  719\n",
      "image:  720\n",
      "image:  721\n",
      "image:  722\n",
      "image:  723\n",
      "image:  724\n",
      "image:  725\n",
      "image:  726\n",
      "image:  727\n",
      "image:  728\n",
      "image:  729\n",
      "image:  730\n",
      "image:  731\n",
      "image:  732\n",
      "image:  733\n",
      "image:  734\n",
      "image:  735\n",
      "image:  736\n",
      "image:  737\n",
      "image:  738\n",
      "image:  739\n",
      "image:  740\n",
      "image:  741\n",
      "image:  742\n",
      "image:  743\n",
      "image:  744\n",
      "image:  745\n",
      "image:  746\n",
      "image:  747\n",
      "image:  748\n",
      "image:  749\n",
      "image:  750\n",
      "image:  751\n",
      "image:  752\n",
      "image:  753\n",
      "image:  754\n",
      "image:  755\n",
      "image:  756\n",
      "image:  757\n",
      "image:  758\n",
      "image:  759\n",
      "image:  760\n",
      "image:  761\n",
      "image:  762\n",
      "image:  763\n",
      "image:  764\n",
      "image:  765\n",
      "image:  766\n",
      "image:  767\n",
      "image:  768\n",
      "image:  769\n",
      "image:  770\n",
      "image:  771\n",
      "image:  772\n",
      "image:  773\n",
      "image:  774\n",
      "image:  775\n",
      "image:  776\n",
      "image:  777\n",
      "image:  778\n",
      "image:  779\n",
      "image:  780\n",
      "image:  781\n",
      "image:  782\n",
      "image:  783\n",
      "image:  784\n",
      "image:  785\n",
      "image:  786\n",
      "image:  787\n",
      "image:  788\n",
      "image:  789\n",
      "image:  790\n",
      "image:  791\n",
      "image:  792\n",
      "image:  793\n",
      "image:  794\n",
      "image:  795\n",
      "image:  796\n",
      "image:  797\n",
      "image:  798\n",
      "image:  799\n",
      "image:  800\n",
      "image:  801\n",
      "image:  802\n",
      "image:  803\n",
      "image:  804\n",
      "image:  805\n",
      "image:  806\n",
      "image:  807\n",
      "image:  808\n",
      "image:  809\n",
      "image:  810\n",
      "image:  811\n",
      "image:  812\n",
      "image:  813\n",
      "image:  814\n",
      "image:  815\n",
      "image:  816\n",
      "image:  817\n",
      "image:  818\n",
      "image:  819\n",
      "image:  820\n",
      "image:  821\n",
      "image:  822\n",
      "image:  823\n",
      "image:  824\n",
      "image:  825\n",
      "image:  826\n",
      "image:  827\n",
      "image:  828\n",
      "image:  829\n",
      "image:  830\n",
      "image:  831\n",
      "image:  832\n",
      "image:  833\n",
      "image:  834\n",
      "image:  835\n",
      "image:  836\n",
      "image:  837\n",
      "image:  838\n",
      "image:  839\n",
      "image:  840\n",
      "image:  841\n",
      "image:  842\n",
      "image:  843\n",
      "image:  844\n",
      "image:  845\n",
      "image:  846\n",
      "image:  847\n",
      "image:  848\n",
      "image:  849\n",
      "image:  850\n",
      "image:  851\n",
      "image:  852\n",
      "image:  853\n",
      "image:  854\n",
      "image:  855\n",
      "image:  856\n",
      "image:  857\n",
      "image:  858\n",
      "image:  859\n",
      "image:  860\n",
      "image:  861\n",
      "image:  862\n",
      "image:  863\n",
      "image:  864\n",
      "image:  865\n",
      "image:  866\n",
      "image:  867\n",
      "image:  868\n",
      "image:  869\n",
      "image:  870\n",
      "image:  871\n",
      "image:  872\n",
      "image:  873\n",
      "image:  874\n",
      "image:  875\n",
      "image:  876\n",
      "image:  877\n",
      "image:  878\n",
      "image:  879\n",
      "image:  880\n",
      "image:  881\n",
      "image:  882\n",
      "image:  883\n",
      "image:  884\n",
      "image:  885\n",
      "image:  886\n",
      "image:  887\n",
      "class name:  healthy\n",
      "image:  888\n",
      "image:  889\n",
      "image:  890\n",
      "image:  891\n",
      "image:  892\n",
      "image:  893\n",
      "image:  894\n",
      "image:  895\n",
      "image:  896\n",
      "image:  897\n",
      "image:  898\n",
      "image:  899\n",
      "image:  900\n",
      "image:  901\n",
      "image:  902\n",
      "image:  903\n",
      "image:  904\n",
      "image:  905\n",
      "image:  906\n",
      "image:  907\n",
      "image:  908\n",
      "image:  909\n",
      "image:  910\n",
      "image:  911\n",
      "image:  912\n",
      "image:  913\n",
      "image:  914\n",
      "image:  915\n",
      "image:  916\n",
      "image:  917\n",
      "image:  918\n",
      "image:  919\n",
      "image:  920\n",
      "image:  921\n",
      "image:  922\n",
      "image:  923\n",
      "image:  924\n",
      "image:  925\n",
      "image:  926\n",
      "image:  927\n",
      "image:  928\n",
      "image:  929\n",
      "image:  930\n",
      "image:  931\n",
      "image:  932\n",
      "image:  933\n",
      "image:  934\n",
      "image:  935\n",
      "image:  936\n",
      "image:  937\n",
      "image:  938\n",
      "image:  939\n",
      "image:  940\n",
      "image:  941\n",
      "image:  942\n",
      "image:  943\n",
      "image:  944\n",
      "image:  945\n",
      "image:  946\n",
      "image:  947\n",
      "image:  948\n",
      "image:  949\n",
      "image:  950\n",
      "image:  951\n",
      "image:  952\n",
      "image:  953\n",
      "image:  954\n",
      "image:  955\n",
      "image:  956\n",
      "image:  957\n",
      "image:  958\n",
      "image:  959\n",
      "image:  960\n",
      "image:  961\n",
      "image:  962\n",
      "image:  963\n",
      "image:  964\n",
      "image:  965\n",
      "image:  966\n",
      "image:  967\n",
      "image:  968\n",
      "image:  969\n",
      "image:  970\n",
      "image:  971\n",
      "image:  972\n",
      "image:  973\n",
      "image:  974\n",
      "image:  975\n",
      "image:  976\n",
      "image:  977\n",
      "image:  978\n",
      "image:  979\n",
      "image:  980\n",
      "image:  981\n",
      "image:  982\n",
      "image:  983\n",
      "image:  984\n",
      "image:  985\n",
      "image:  986\n",
      "image:  987\n",
      "image:  988\n",
      "image:  989\n",
      "image:  990\n",
      "image:  991\n",
      "image:  992\n",
      "image:  993\n",
      "image:  994\n",
      "image:  995\n",
      "image:  996\n",
      "image:  997\n",
      "image:  998\n",
      "image:  999\n",
      "image:  1000\n",
      "image:  1001\n",
      "image:  1002\n",
      "image:  1003\n",
      "image:  1004\n",
      "image:  1005\n",
      "image:  1006\n",
      "image:  1007\n",
      "image:  1008\n",
      "image:  1009\n",
      "image:  1010\n",
      "image:  1011\n",
      "image:  1012\n",
      "image:  1013\n",
      "image:  1014\n",
      "image:  1015\n",
      "image:  1016\n",
      "image:  1017\n",
      "image:  1018\n",
      "image:  1019\n",
      "image:  1020\n",
      "image:  1021\n",
      "image:  1022\n",
      "image:  1023\n",
      "image:  1024\n",
      "image:  1025\n",
      "image:  1026\n",
      "image:  1027\n",
      "image:  1028\n",
      "image:  1029\n",
      "image:  1030\n",
      "image:  1031\n",
      "image:  1032\n",
      "image:  1033\n",
      "image:  1034\n",
      "image:  1035\n",
      "image:  1036\n",
      "image:  1037\n",
      "image:  1038\n",
      "image:  1039\n",
      "image:  1040\n",
      "image:  1041\n",
      "image:  1042\n",
      "image:  1043\n",
      "image:  1044\n",
      "image:  1045\n",
      "image:  1046\n",
      "image:  1047\n",
      "image:  1048\n",
      "image:  1049\n",
      "image:  1050\n",
      "image:  1051\n",
      "image:  1052\n",
      "image:  1053\n",
      "image:  1054\n",
      "image:  1055\n",
      "image:  1056\n",
      "image:  1057\n",
      "image:  1058\n",
      "image:  1059\n",
      "image:  1060\n",
      "image:  1061\n",
      "image:  1062\n",
      "image:  1063\n",
      "image:  1064\n",
      "image:  1065\n",
      "image:  1066\n",
      "image:  1067\n",
      "image:  1068\n",
      "image:  1069\n",
      "image:  1070\n",
      "image:  1071\n",
      "image:  1072\n",
      "image:  1073\n",
      "image:  1074\n",
      "image:  1075\n",
      "image:  1076\n",
      "image:  1077\n",
      "image:  1078\n",
      "image:  1079\n",
      "image:  1080\n",
      "image:  1081\n",
      "image:  1082\n",
      "image:  1083\n",
      "image:  1084\n",
      "image:  1085\n",
      "image:  1086\n",
      "image:  1087\n",
      "image:  1088\n",
      "image:  1089\n",
      "image:  1090\n",
      "image:  1091\n",
      "image:  1092\n",
      "image:  1093\n",
      "image:  1094\n",
      "image:  1095\n",
      "image:  1096\n",
      "image:  1097\n",
      "image:  1098\n",
      "image:  1099\n",
      "image:  1100\n",
      "image:  1101\n",
      "image:  1102\n",
      "image:  1103\n",
      "image:  1104\n",
      "image:  1105\n",
      "image:  1106\n",
      "image:  1107\n",
      "image:  1108\n",
      "image:  1109\n",
      "image:  1110\n",
      "image:  1111\n",
      "image:  1112\n",
      "image:  1113\n",
      "image:  1114\n",
      "image:  1115\n",
      "image:  1116\n",
      "image:  1117\n",
      "image:  1118\n",
      "image:  1119\n",
      "image:  1120\n",
      "image:  1121\n",
      "image:  1122\n",
      "image:  1123\n",
      "image:  1124\n",
      "image:  1125\n",
      "image:  1126\n",
      "image:  1127\n",
      "image:  1128\n",
      "image:  1129\n",
      "image:  1130\n",
      "image:  1131\n",
      "image:  1132\n",
      "image:  1133\n",
      "image:  1134\n",
      "image:  1135\n",
      "image:  1136\n",
      "image:  1137\n",
      "image:  1138\n",
      "image:  1139\n",
      "image:  1140\n",
      "image:  1141\n",
      "image:  1142\n",
      "image:  1143\n",
      "image:  1144\n",
      "image:  1145\n",
      "image:  1146\n",
      "image:  1147\n",
      "image:  1148\n",
      "image:  1149\n",
      "image:  1150\n",
      "image:  1151\n",
      "image:  1152\n",
      "image:  1153\n",
      "image:  1154\n",
      "image:  1155\n",
      "image:  1156\n",
      "image:  1157\n",
      "image:  1158\n",
      "image:  1159\n",
      "image:  1160\n",
      "image:  1161\n",
      "image:  1162\n",
      "image:  1163\n",
      "image:  1164\n",
      "image:  1165\n",
      "image:  1166\n",
      "image:  1167\n",
      "image:  1168\n",
      "image:  1169\n",
      "image:  1170\n",
      "image:  1171\n",
      "image:  1172\n",
      "image:  1173\n",
      "image:  1174\n",
      "image:  1175\n",
      "image:  1176\n",
      "image:  1177\n",
      "image:  1178\n",
      "image:  1179\n",
      "image:  1180\n",
      "image:  1181\n",
      "image:  1182\n",
      "image:  1183\n",
      "image:  1184\n",
      "image:  1185\n",
      "image:  1186\n",
      "image:  1187\n",
      "image:  1188\n",
      "image:  1189\n",
      "image:  1190\n",
      "image:  1191\n",
      "image:  1192\n",
      "image:  1193\n",
      "image:  1194\n",
      "image:  1195\n",
      "image:  1196\n",
      "image:  1197\n",
      "image:  1198\n",
      "image:  1199\n",
      "image:  1200\n",
      "image:  1201\n",
      "image:  1202\n",
      "image:  1203\n",
      "image:  1204\n",
      "image:  1205\n",
      "image:  1206\n",
      "image:  1207\n",
      "image:  1208\n",
      "image:  1209\n",
      "image:  1210\n",
      "image:  1211\n",
      "image:  1212\n",
      "image:  1213\n",
      "image:  1214\n",
      "image:  1215\n",
      "image:  1216\n",
      "image:  1217\n",
      "image:  1218\n",
      "image:  1219\n",
      "image:  1220\n",
      "image:  1221\n",
      "image:  1222\n",
      "image:  1223\n",
      "image:  1224\n",
      "image:  1225\n",
      "image:  1226\n",
      "image:  1227\n",
      "image:  1228\n",
      "image:  1229\n",
      "image:  1230\n",
      "image:  1231\n",
      "image:  1232\n",
      "image:  1233\n",
      "image:  1234\n",
      "image:  1235\n",
      "image:  1236\n",
      "image:  1237\n",
      "image:  1238\n",
      "image:  1239\n",
      "image:  1240\n",
      "image:  1241\n",
      "image:  1242\n",
      "image:  1243\n",
      "image:  1244\n",
      "image:  1245\n",
      "image:  1246\n",
      "image:  1247\n",
      "image:  1248\n",
      "image:  1249\n",
      "image:  1250\n",
      "image:  1251\n",
      "image:  1252\n",
      "image:  1253\n",
      "image:  1254\n",
      "image:  1255\n",
      "image:  1256\n",
      "image:  1257\n",
      "image:  1258\n",
      "image:  1259\n",
      "image:  1260\n",
      "image:  1261\n",
      "image:  1262\n",
      "image:  1263\n",
      "image:  1264\n",
      "image:  1265\n",
      "image:  1266\n",
      "image:  1267\n",
      "image:  1268\n",
      "image:  1269\n",
      "image:  1270\n",
      "image:  1271\n",
      "image:  1272\n",
      "image:  1273\n",
      "image:  1274\n",
      "image:  1275\n",
      "image:  1276\n",
      "image:  1277\n",
      "image:  1278\n",
      "image:  1279\n",
      "image:  1280\n",
      "image:  1281\n",
      "image:  1282\n",
      "image:  1283\n",
      "image:  1284\n",
      "image:  1285\n",
      "image:  1286\n",
      "image:  1287\n",
      "image:  1288\n",
      "image:  1289\n",
      "image:  1290\n",
      "image:  1291\n",
      "image:  1292\n",
      "image:  1293\n",
      "image:  1294\n",
      "image:  1295\n",
      "image:  1296\n",
      "image:  1297\n",
      "image:  1298\n",
      "image:  1299\n",
      "image:  1300\n",
      "image:  1301\n",
      "image:  1302\n",
      "image:  1303\n",
      "image:  1304\n",
      "image:  1305\n",
      "image:  1306\n",
      "image:  1307\n",
      "image:  1308\n",
      "image:  1309\n",
      "image:  1310\n",
      "image:  1311\n",
      "image:  1312\n",
      "image:  1313\n",
      "image:  1314\n",
      "image:  1315\n",
      "image:  1316\n",
      "image:  1317\n",
      "image:  1318\n",
      "image:  1319\n",
      "image:  1320\n",
      "image:  1321\n",
      "image:  1322\n",
      "image:  1323\n",
      "image:  1324\n",
      "image:  1325\n",
      "image:  1326\n",
      "image:  1327\n",
      "image:  1328\n",
      "image:  1329\n",
      "image:  1330\n",
      "image:  1331\n",
      "image:  1332\n",
      "image:  1333\n",
      "image:  1334\n",
      "image:  1335\n",
      "image:  1336\n",
      "image:  1337\n",
      "image:  1338\n",
      "image:  1339\n",
      "image:  1340\n",
      "image:  1341\n",
      "image:  1342\n",
      "image:  1343\n",
      "image:  1344\n",
      "image:  1345\n",
      "image:  1346\n",
      "image:  1347\n",
      "image:  1348\n",
      "image:  1349\n",
      "image:  1350\n",
      "image:  1351\n",
      "image:  1352\n",
      "image:  1353\n",
      "image:  1354\n",
      "image:  1355\n",
      "image:  1356\n",
      "image:  1357\n",
      "image:  1358\n",
      "image:  1359\n",
      "image:  1360\n",
      "image:  1361\n",
      "image:  1362\n",
      "image:  1363\n",
      "image:  1364\n",
      "image:  1365\n",
      "image:  1366\n",
      "image:  1367\n",
      "image:  1368\n",
      "image:  1369\n",
      "image:  1370\n",
      "image:  1371\n",
      "image:  1372\n",
      "image:  1373\n",
      "image:  1374\n",
      "image:  1375\n",
      "image:  1376\n",
      "image:  1377\n",
      "image:  1378\n",
      "image:  1379\n",
      "image:  1380\n",
      "image:  1381\n",
      "image:  1382\n",
      "image:  1383\n",
      "image:  1384\n",
      "image:  1385\n",
      "image:  1386\n",
      "image:  1387\n",
      "image:  1388\n",
      "image:  1389\n",
      "image:  1390\n",
      "image:  1391\n",
      "image:  1392\n",
      "image:  1393\n",
      "image:  1394\n",
      "image:  1395\n",
      "image:  1396\n",
      "image:  1397\n",
      "image:  1398\n",
      "image:  1399\n",
      "image:  1400\n",
      "image:  1401\n",
      "image:  1402\n",
      "image:  1403\n",
      "image:  1404\n",
      "image:  1405\n",
      "image:  1406\n",
      "image:  1407\n",
      "image:  1408\n",
      "image:  1409\n",
      "image:  1410\n",
      "image:  1411\n",
      "image:  1412\n",
      "image:  1413\n",
      "image:  1414\n",
      "image:  1415\n",
      "image:  1416\n",
      "image:  1417\n",
      "updating k:  0\n",
      "3\n",
      "image:  1418\n",
      "image:  1419\n",
      "image:  1420\n",
      "image:  1421\n",
      "image:  1422\n",
      "image:  1423\n",
      "image:  1424\n",
      "image:  1425\n",
      "image:  1426\n",
      "image:  1427\n",
      "image:  1428\n",
      "image:  1429\n",
      "image:  1430\n",
      "image:  1431\n",
      "image:  1432\n",
      "image:  1433\n",
      "image:  1434\n",
      "image:  1435\n",
      "image:  1436\n",
      "image:  1437\n",
      "image:  1438\n",
      "image:  1439\n",
      "image:  1440\n",
      "image:  1441\n",
      "image:  1442\n",
      "image:  1443\n",
      "image:  1444\n",
      "image:  1445\n",
      "image:  1446\n",
      "image:  1447\n",
      "image:  1448\n",
      "image:  1449\n",
      "image:  1450\n",
      "image:  1451\n",
      "image:  1452\n",
      "image:  1453\n",
      "image:  1454\n",
      "image:  1455\n",
      "image:  1456\n",
      "image:  1457\n",
      "image:  1458\n",
      "image:  1459\n",
      "image:  1460\n",
      "image:  1461\n",
      "image:  1462\n",
      "image:  1463\n",
      "image:  1464\n",
      "image:  1465\n",
      "image:  1466\n",
      "image:  1467\n",
      "image:  1468\n",
      "image:  1469\n",
      "image:  1470\n",
      "image:  1471\n",
      "image:  1472\n",
      "image:  1473\n",
      "image:  1474\n",
      "image:  1475\n",
      "image:  1476\n",
      "image:  1477\n",
      "image:  1478\n",
      "image:  1479\n",
      "image:  1480\n",
      "image:  1481\n",
      "image:  1482\n",
      "image:  1483\n",
      "image:  1484\n",
      "image:  1485\n",
      "image:  1486\n",
      "image:  1487\n",
      "image:  1488\n",
      "image:  1489\n",
      "image:  1490\n",
      "image:  1491\n",
      "image:  1492\n",
      "image:  1493\n",
      "image:  1494\n",
      "image:  1495\n",
      "image:  1496\n",
      "image:  1497\n",
      "image:  1498\n",
      "image:  1499\n",
      "image:  1500\n",
      "image:  1501\n",
      "image:  1502\n",
      "image:  1503\n",
      "image:  1504\n",
      "image:  1505\n",
      "image:  1506\n",
      "image:  1507\n",
      "image:  1508\n",
      "image:  1509\n",
      "image:  1510\n",
      "image:  1511\n",
      "image:  1512\n",
      "image:  1513\n",
      "image:  1514\n",
      "image:  1515\n",
      "image:  1516\n",
      "image:  1517\n",
      "image:  1518\n",
      "image:  1519\n",
      "image:  1520\n",
      "image:  1521\n",
      "image:  1522\n",
      "image:  1523\n",
      "image:  1524\n",
      "image:  1525\n",
      "image:  1526\n",
      "image:  1527\n",
      "image:  1528\n",
      "image:  1529\n",
      "image:  1530\n",
      "image:  1531\n",
      "image:  1532\n",
      "image:  1533\n",
      "image:  1534\n",
      "image:  1535\n",
      "image:  1536\n",
      "image:  1537\n",
      "image:  1538\n",
      "image:  1539\n",
      "image:  1540\n",
      "image:  1541\n",
      "image:  1542\n",
      "image:  1543\n",
      "image:  1544\n",
      "image:  1545\n",
      "image:  1546\n",
      "image:  1547\n",
      "image:  1548\n",
      "image:  1549\n",
      "updating k:  1\n",
      "3\n",
      "image:  1550\n",
      "image:  1551\n",
      "image:  1552\n",
      "image:  1553\n",
      "image:  1554\n",
      "image:  1555\n",
      "image:  1556\n",
      "image:  1557\n",
      "image:  1558\n",
      "image:  1559\n",
      "image:  1560\n",
      "image:  1561\n",
      "image:  1562\n",
      "image:  1563\n",
      "image:  1564\n",
      "image:  1565\n",
      "image:  1566\n",
      "image:  1567\n",
      "image:  1568\n",
      "image:  1569\n",
      "image:  1570\n",
      "image:  1571\n",
      "image:  1572\n",
      "image:  1573\n",
      "image:  1574\n",
      "image:  1575\n",
      "image:  1576\n",
      "image:  1577\n",
      "image:  1578\n",
      "image:  1579\n",
      "image:  1580\n",
      "image:  1581\n",
      "image:  1582\n",
      "image:  1583\n",
      "image:  1584\n",
      "image:  1585\n",
      "image:  1586\n",
      "image:  1587\n",
      "image:  1588\n",
      "image:  1589\n",
      "image:  1590\n",
      "image:  1591\n",
      "image:  1592\n",
      "image:  1593\n",
      "image:  1594\n",
      "image:  1595\n",
      "image:  1596\n",
      "image:  1597\n",
      "image:  1598\n",
      "image:  1599\n",
      "image:  1600\n",
      "image:  1601\n",
      "image:  1602\n",
      "image:  1603\n",
      "image:  1604\n",
      "image:  1605\n",
      "image:  1606\n",
      "image:  1607\n",
      "image:  1608\n",
      "image:  1609\n",
      "image:  1610\n",
      "image:  1611\n",
      "image:  1612\n",
      "image:  1613\n",
      "image:  1614\n",
      "image:  1615\n",
      "image:  1616\n",
      "image:  1617\n",
      "image:  1618\n",
      "image:  1619\n",
      "image:  1620\n",
      "image:  1621\n",
      "image:  1622\n",
      "image:  1623\n",
      "image:  1624\n",
      "image:  1625\n",
      "image:  1626\n",
      "image:  1627\n",
      "image:  1628\n",
      "image:  1629\n",
      "image:  1630\n",
      "image:  1631\n",
      "image:  1632\n",
      "image:  1633\n",
      "image:  1634\n",
      "image:  1635\n",
      "image:  1636\n",
      "image:  1637\n",
      "image:  1638\n",
      "image:  1639\n",
      "image:  1640\n",
      "image:  1641\n",
      "image:  1642\n",
      "image:  1643\n",
      "image:  1644\n",
      "image:  1645\n",
      "image:  1646\n",
      "image:  1647\n",
      "image:  1648\n",
      "image:  1649\n",
      "image:  1650\n",
      "image:  1651\n",
      "image:  1652\n",
      "image:  1653\n",
      "image:  1654\n",
      "image:  1655\n",
      "image:  1656\n",
      "image:  1657\n",
      "image:  1658\n",
      "image:  1659\n",
      "image:  1660\n",
      "image:  1661\n",
      "image:  1662\n",
      "image:  1663\n",
      "image:  1664\n",
      "image:  1665\n",
      "image:  1666\n",
      "image:  1667\n",
      "image:  1668\n",
      "image:  1669\n",
      "image:  1670\n",
      "image:  1671\n",
      "image:  1672\n",
      "image:  1673\n",
      "image:  1674\n",
      "image:  1675\n",
      "image:  1676\n",
      "image:  1677\n",
      "image:  1678\n",
      "image:  1679\n",
      "image:  1680\n",
      "image:  1681\n",
      "image:  1682\n",
      "image:  1683\n",
      "image:  1684\n",
      "image:  1685\n",
      "image:  1686\n",
      "image:  1687\n",
      "image:  1688\n",
      "image:  1689\n",
      "image:  1690\n",
      "image:  1691\n",
      "image:  1692\n",
      "image:  1693\n",
      "image:  1694\n",
      "image:  1695\n",
      "image:  1696\n",
      "image:  1697\n",
      "image:  1698\n",
      "image:  1699\n",
      "image:  1700\n",
      "image:  1701\n",
      "image:  1702\n",
      "image:  1703\n",
      "image:  1704\n",
      "image:  1705\n",
      "image:  1706\n",
      "image:  1707\n",
      "image:  1708\n",
      "image:  1709\n",
      "image:  1710\n",
      "image:  1711\n",
      "image:  1712\n",
      "image:  1713\n",
      "image:  1714\n",
      "image:  1715\n",
      "image:  1716\n",
      "image:  1717\n",
      "image:  1718\n",
      "image:  1719\n",
      "image:  1720\n",
      "image:  1721\n",
      "image:  1722\n",
      "image:  1723\n",
      "image:  1724\n",
      "image:  1725\n",
      "image:  1726\n",
      "image:  1727\n",
      "image:  1728\n",
      "image:  1729\n",
      "image:  1730\n",
      "image:  1731\n",
      "image:  1732\n",
      "image:  1733\n",
      "image:  1734\n",
      "image:  1735\n",
      "image:  1736\n",
      "image:  1737\n",
      "image:  1738\n",
      "image:  1739\n",
      "image:  1740\n",
      "image:  1741\n",
      "image:  1742\n",
      "image:  1743\n",
      "image:  1744\n",
      "image:  1745\n",
      "image:  1746\n",
      "image:  1747\n",
      "image:  1748\n",
      "image:  1749\n",
      "image:  1750\n",
      "image:  1751\n",
      "image:  1752\n",
      "image:  1753\n",
      "image:  1754\n",
      "image:  1755\n",
      "image:  1756\n",
      "image:  1757\n",
      "image:  1758\n",
      "image:  1759\n",
      "image:  1760\n",
      "image:  1761\n",
      "image:  1762\n",
      "image:  1763\n",
      "image:  1764\n",
      "image:  1765\n",
      "image:  1766\n",
      "image:  1767\n",
      "image:  1768\n",
      "image:  1769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image:  1341\n",
      "image:  1342\n",
      "image:  1343\n",
      "image:  1344\n",
      "image:  1345\n",
      "image:  1346\n",
      "image:  1347\n",
      "image:  1348\n",
      "image:  1349\n",
      "image:  1350\n",
      "image:  1351\n",
      "image:  1352\n",
      "image:  1353\n",
      "image:  1354\n",
      "image:  1355\n",
      "image:  1356\n",
      "image:  1357\n",
      "image:  1358\n",
      "image:  1359\n",
      "image:  1360\n",
      "image:  1361\n",
      "image:  1362\n",
      "image:  1363\n",
      "image:  1364\n",
      "image:  1365\n",
      "image:  1366\n",
      "image:  1367\n",
      "image:  1368\n",
      "image:  1369\n",
      "image:  1370\n",
      "image:  1371\n",
      "image:  1372\n",
      "image:  1373\n",
      "image:  1374\n",
      "image:  1375\n",
      "image:  1376\n",
      "image:  1377\n",
      "image:  1378\n",
      "image:  1379\n",
      "image:  1380\n",
      "image:  1381\n",
      "image:  1382\n",
      "image:  1383\n",
      "image:  1384\n",
      "image:  1385\n",
      "image:  1386\n",
      "image:  1387\n",
      "image:  1388\n",
      "image:  1389\n",
      "image:  1390\n",
      "image:  1391\n",
      "image:  1392\n",
      "image:  1393\n",
      "image:  1394\n",
      "image:  1395\n",
      "image:  1396\n",
      "image:  1397\n",
      "image:  1398\n",
      "image:  1399\n",
      "image:  1400\n",
      "image:  1401\n",
      "image:  1402\n",
      "image:  1403\n",
      "image:  1404\n",
      "image:  1405\n",
      "image:  1406\n",
      "image:  1407\n",
      "image:  1408\n",
      "image:  1409\n",
      "image:  1410\n",
      "image:  1411\n",
      "image:  1412\n",
      "image:  1413\n",
      "image:  1414\n",
      "image:  1415\n",
      "image:  1416\n",
      "image:  1417\n",
      "updating k:  0\n",
      "3\n",
      "image:  1418\n",
      "image:  1419\n",
      "image:  1420\n",
      "image:  1421\n",
      "image:  1422\n",
      "image:  1423\n",
      "image:  1424\n",
      "image:  1425\n",
      "image:  1426\n",
      "image:  1427\n",
      "image:  1428\n",
      "image:  1429\n",
      "image:  1430\n",
      "image:  1431\n",
      "image:  1432\n",
      "image:  1433\n",
      "image:  1434\n",
      "image:  1435\n",
      "image:  1436\n",
      "image:  1437\n",
      "image:  1438\n",
      "image:  1439\n",
      "image:  1440\n",
      "image:  1441\n",
      "image:  1442\n",
      "image:  1443\n",
      "image:  1444\n",
      "image:  1445\n",
      "image:  1446\n",
      "image:  1447\n",
      "image:  1448\n",
      "image:  1449\n",
      "image:  1450\n",
      "image:  1451\n",
      "image:  1452\n",
      "image:  1453\n",
      "image:  1454\n",
      "image:  1455\n",
      "image:  1456\n",
      "image:  1457\n",
      "image:  1458\n",
      "image:  1459\n",
      "image:  1460\n",
      "image:  1461\n",
      "image:  1462\n",
      "image:  1463\n",
      "image:  1464\n",
      "image:  1465\n",
      "image:  1466\n",
      "image:  1467\n",
      "image:  1468\n",
      "image:  1469\n",
      "image:  1470\n",
      "image:  1471\n",
      "image:  1472\n",
      "image:  1473\n",
      "image:  1474\n",
      "image:  1475\n",
      "image:  1476\n",
      "image:  1477\n",
      "image:  1478\n",
      "image:  1479\n",
      "image:  1480\n",
      "image:  1481\n",
      "image:  1482\n",
      "image:  1483\n",
      "image:  1484\n",
      "image:  1485\n",
      "image:  1486\n",
      "image:  1487\n",
      "image:  1488\n",
      "image:  1489\n",
      "image:  1490\n",
      "image:  1491\n",
      "image:  1492\n",
      "image:  1493\n",
      "image:  1494\n",
      "image:  1495\n",
      "image:  1496\n",
      "image:  1497\n",
      "image:  1498\n",
      "image:  1499\n",
      "image:  1500\n",
      "image:  1501\n",
      "image:  1502\n",
      "image:  1503\n",
      "image:  1504\n",
      "image:  1505\n",
      "image:  1506\n",
      "image:  1507\n",
      "image:  1508\n",
      "image:  1509\n",
      "image:  1510\n",
      "image:  1511\n",
      "image:  1512\n",
      "image:  1513\n",
      "image:  1514\n",
      "image:  1515\n",
      "image:  1516\n",
      "image:  1517\n",
      "image:  1518\n",
      "image:  1519\n",
      "image:  1520\n",
      "image:  1521\n",
      "image:  1522\n",
      "image:  1523\n",
      "image:  1524\n",
      "image:  1525\n",
      "image:  1526\n",
      "image:  1527\n",
      "image:  1528\n",
      "image:  1529\n",
      "image:  1530\n",
      "image:  1531\n",
      "image:  1532\n",
      "image:  1533\n",
      "image:  1534\n",
      "image:  1535\n",
      "image:  1536\n",
      "image:  1537\n",
      "image:  1538\n",
      "image:  1539\n",
      "image:  1540\n",
      "image:  1541\n",
      "image:  1542\n",
      "image:  1543\n",
      "image:  1544\n",
      "image:  1545\n",
      "image:  1546\n",
      "image:  1547\n",
      "image:  1548\n",
      "image:  1549\n",
      "updating k:  1\n",
      "3\n",
      "image:  1550\n",
      "image:  1551\n",
      "image:  1552\n",
      "image:  1553\n",
      "image:  1554\n",
      "image:  1555\n",
      "image:  1556\n",
      "image:  1557\n",
      "image:  1558\n",
      "image:  1559\n",
      "image:  1560\n",
      "image:  1561\n",
      "image:  1562\n",
      "image:  1563\n",
      "image:  1564\n",
      "image:  1565\n",
      "image:  1566\n",
      "image:  1567\n",
      "image:  1568\n",
      "image:  1569\n",
      "image:  1570\n",
      "image:  1571\n",
      "image:  1572\n",
      "image:  1573\n",
      "image:  1574\n",
      "image:  1575\n",
      "image:  1576\n",
      "image:  1577\n",
      "image:  1578\n",
      "image:  1579\n",
      "image:  1580\n",
      "image:  1581\n",
      "image:  1582\n",
      "image:  1583\n",
      "image:  1584\n",
      "image:  1585\n",
      "image:  1586\n",
      "image:  1587\n",
      "image:  1588\n",
      "image:  1589\n",
      "image:  1590\n",
      "image:  1591\n",
      "image:  1592\n",
      "image:  1593\n",
      "image:  1594\n",
      "image:  1595\n",
      "image:  1596\n",
      "image:  1597\n",
      "image:  1598\n",
      "image:  1599\n",
      "image:  1600\n",
      "image:  1601\n",
      "image:  1602\n",
      "image:  1603\n",
      "image:  1604\n",
      "image:  1605\n",
      "image:  1606\n",
      "image:  1607\n",
      "image:  1608\n",
      "image:  1609\n",
      "image:  1610\n",
      "image:  1611\n",
      "image:  1612\n",
      "image:  1613\n",
      "image:  1614\n",
      "image:  1615\n",
      "image:  1616\n",
      "image:  1617\n",
      "image:  1618\n",
      "image:  1619\n",
      "image:  1620\n",
      "image:  1621\n",
      "image:  1622\n",
      "image:  1623\n",
      "image:  1624\n",
      "image:  1625\n",
      "image:  1626\n",
      "image:  1627\n",
      "image:  1628\n",
      "image:  1629\n",
      "image:  1630\n",
      "image:  1631\n",
      "image:  1632\n",
      "image:  1633\n",
      "image:  1634\n",
      "image:  1635\n",
      "image:  1636\n",
      "image:  1637\n",
      "image:  1638\n",
      "image:  1639\n",
      "image:  1640\n",
      "image:  1641\n",
      "image:  1642\n",
      "image:  1643\n",
      "image:  1644\n",
      "image:  1645\n",
      "image:  1646\n",
      "image:  1647\n",
      "image:  1648\n",
      "image:  1649\n",
      "image:  1650\n",
      "image:  1651\n",
      "image:  1652\n",
      "image:  1653\n",
      "image:  1654\n",
      "image:  1655\n",
      "image:  1656\n",
      "image:  1657\n",
      "image:  1658\n",
      "image:  1659\n",
      "image:  1660\n",
      "image:  1661\n",
      "image:  1662\n",
      "image:  1663\n",
      "image:  1664\n",
      "image:  1665\n",
      "image:  1666\n",
      "image:  1667\n",
      "image:  1668\n",
      "image:  1669\n",
      "image:  1670\n",
      "image:  1671\n",
      "image:  1672\n",
      "image:  1673\n",
      "image:  1674\n",
      "image:  1675\n",
      "image:  1676\n",
      "image:  1677\n",
      "image:  1678\n",
      "image:  1679\n",
      "image:  1680\n",
      "image:  1681\n",
      "image:  1682\n",
      "image:  1683\n",
      "image:  1684\n",
      "image:  1685\n",
      "image:  1686\n",
      "image:  1687\n",
      "image:  1688\n",
      "image:  1689\n",
      "image:  1690\n",
      "image:  1691\n",
      "image:  1692\n",
      "image:  1693\n",
      "image:  1694\n",
      "image:  1695\n",
      "image:  1696\n",
      "image:  1697\n",
      "image:  1698\n",
      "image:  1699\n",
      "image:  1700\n",
      "image:  1701\n",
      "image:  1702\n",
      "image:  1703\n",
      "image:  1704\n",
      "image:  1705\n",
      "image:  1706\n",
      "image:  1707\n",
      "image:  1708\n",
      "image:  1709\n",
      "image:  1710\n",
      "image:  1711\n",
      "image:  1712\n",
      "image:  1713\n",
      "image:  1714\n",
      "image:  1715\n",
      "image:  1716\n",
      "image:  1717\n",
      "image:  1718\n",
      "image:  1719\n",
      "image:  1720\n",
      "image:  1721\n",
      "image:  1722\n",
      "image:  1723\n",
      "image:  1724\n",
      "image:  1725\n",
      "image:  1726\n",
      "image:  1727\n",
      "image:  1728\n",
      "image:  1729\n",
      "image:  1730\n",
      "image:  1731\n",
      "image:  1732\n",
      "image:  1733\n",
      "image:  1734\n",
      "image:  1735\n",
      "image:  1736\n",
      "image:  1737\n",
      "image:  1738\n",
      "image:  1739\n",
      "image:  1740\n",
      "image:  1741\n",
      "image:  1742\n",
      "image:  1743\n",
      "image:  1744\n",
      "image:  1745\n",
      "image:  1746\n",
      "image:  1747\n",
      "image:  1748\n",
      "image:  1749\n",
      "image:  1750\n",
      "image:  1751\n",
      "image:  1752\n",
      "image:  1753\n",
      "image:  1754\n",
      "image:  1755\n",
      "image:  1756\n",
      "image:  1757\n",
      "image:  1758\n",
      "image:  1759\n",
      "image:  1760\n",
      "image:  1761\n",
      "image:  1762\n",
      "image:  1763\n",
      "image:  1764\n",
      "image:  1765\n",
      "image:  1766\n",
      "image:  1767\n",
      "image:  1768\n",
      "image:  1769\n"
     ]
    }
   ],
   "source": [
    "# SPLIT DATASET (and resize) *************************************\n",
    "print(\"Split dataset.\")\n",
    "\n",
    "i=0\n",
    "j=0\n",
    "k=0\n",
    "for class_name in CLASS_NAMES: # \"j\" cambia con il tipo di pianta [0,3]\n",
    "\n",
    "    print(\"class name: \", class_name)\n",
    "\n",
    "    contatore_samples = 0\n",
    "    k=0\n",
    "\n",
    "    array = sorted(os.listdir(dir_original + '/' + class_name))\n",
    "    #random.shuffle(array)\n",
    "\n",
    "    for image_name in array: # \"contatore\" si azzera ad ogni campo 'train' 'validation' 'test'\n",
    "\n",
    "        print(\"image: \", i)\n",
    "        i=i+1\n",
    "        \n",
    "        if contatore_samples==N_samples[j][k] and k+1  < len(N_samples[j]):    # \"k\" cambia con train, validation, e test\n",
    "            print(\"updating k: \", k)\n",
    "            print(len(N_samples[j]))\n",
    "            k+=1\n",
    "            contatore_samples=0\n",
    "\n",
    "\n",
    "        img=Image.open(dir_original +'/'+class_name+'/'+image_name)\n",
    "        l,_ = img.size\n",
    "        l=int(l)\n",
    "        \n",
    "        \n",
    "        if l==1080 or l==720:\n",
    "        \n",
    "            transposed = img.transpose(Image.ROTATE_90)\n",
    "            transposed.thumbnail(size)\n",
    "            transposed.save(dir_processed+'/'+set_samples[k]+'/'+class_name+'/'+image_name)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            img.thumbnail(size)\n",
    "            img.save(dir_processed+'/'+set_samples[k]+'/'+class_name+'/'+image_name)\n",
    "\n",
    "        contatore_samples+=1\n",
    "\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada4b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train root ./data_processed\\train\n",
      "Directory './checkpoints_30_32_0001/' created\n"
     ]
    }
   ],
   "source": [
    "PATH_DATASET = './data_processed'\n",
    " \n",
    "train_root_dir=os.path.join(PATH_DATASET, 'train')   # Example: \"../../GastroVision22Aug/train\"\n",
    "val_root_dir= os.path.join(PATH_DATASET, 'validation') # Example: \"../../GastroVision22Aug/val\"\n",
    "test_root_dir= os.path.join(PATH_DATASET, 'test') # Example: \"../../GastroVision22Aug/test\"\n",
    "model_path=r'./checkpoints_30_32_0001/'  # set path to the folder that will store model's checkpoints\n",
    "\n",
    "n_classes=2  # number of classes used for training\n",
    "\n",
    "global val_f1_max\n",
    "\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(os.path.dirname(model_path)):\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "    \n",
    "print('train root', train_root_dir)\n",
    "\n",
    "print(\"Directory '% s' created\" % model_path)\n",
    "filename='results_e'+str(max_epochs)+'_'+'b'+str(batch_size)+'_'+'lr'+str(lr)+'_'+'densenet121'   #filename used for saving epoch-wise training details and test results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4886a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################\n",
    "# # Training\n",
    "# ####################################\n",
    "\n",
    "trans={\n",
    " # Train uses data augmentation\n",
    " 'train':\n",
    " transforms.Compose([\n",
    "     #transforms.Resize((224, 224)),\n",
    "     #transforms.RandomRotation(degrees=15),\n",
    "     #transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     #transforms.Normalize([0.4762, 0.3054, 0.2368], [0.3345, 0.2407, 0.2164])\n",
    "]),\n",
    " # Validation does not use augmentation\n",
    " 'valid':\n",
    " transforms.Compose([\n",
    "#          transforms.Resize((224,224)),\n",
    "     transforms.ToTensor(),\n",
    "#          transforms.Normalize([0.4762, 0.3054, 0.2368], [0.3345, 0.2407, 0.2164])\n",
    " ]),\n",
    "\n",
    " # Test does not use augmentation\n",
    " 'test':\n",
    " transforms.Compose([\n",
    "#          transforms.Resize((224,224)),\n",
    "     transforms.ToTensor(),\n",
    "#          transforms.Normalize([0.4762, 0.3054, 0.2368], [0.3345, 0.2407, 0.2164])\n",
    " ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cef8676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train:\n",
    "    def __init__(self):\n",
    "\n",
    "#         transform=trans['valid']\n",
    "        #Generators\n",
    "        training_dataset= datasets.ImageFolder(train_root_dir, transform=trans['train'])\n",
    "        validation_dataset= datasets.ImageFolder(val_root_dir, transform=trans['valid'])\n",
    "        test_dataset= datasets.ImageFolder(test_root_dir, transform=trans['test'])\n",
    "        \n",
    "        self.training_generator=data.DataLoader(training_dataset,batch_size,shuffle=True) # ** unpacks a dictionary into keyword arguments\n",
    "        self.validation_generator=data.DataLoader(validation_dataset,batch_size)\n",
    "        self.test_generator=data.DataLoader(test_dataset,batch_size)\n",
    "       \n",
    "        print('Number of Training set images:{}'.format(len(training_dataset)))\n",
    "        print('Number of Validation set images:{}'.format(len(validation_dataset)))\n",
    "        print('Number of Test set images:{}'.format(len(test_dataset)))\n",
    "        \n",
    "    def train_net(self):\n",
    "        \n",
    "        #Initialize model\n",
    "        model = torchvision.models.densenet121(weights=True).to(device)   # make weights=True if you want to download pre-trained weights\n",
    "        \n",
    "        \n",
    "#         model.load_state_dict(torch.load('./densenet121.pth',map_location='cuda'))   # provide a .pth path for already downloaded weights; otherwise comment this line out\n",
    "        \n",
    "        \n",
    "        # Option to freeze model weights\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True                       # Set param.requires_grad = False if you want to train only the last updated layers and freeze all other layers\n",
    "        \n",
    "        n_inputs = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, n_classes),                  \n",
    "                      nn.LogSoftmax(dim=1))\n",
    "        \n",
    "       \n",
    "        model.to(device)\n",
    "        optimizer=optim.Adam(model.parameters(), lr, weight_decay=1e-4)\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=4,verbose=True)\n",
    "        criterion = nn.NLLLoss()\n",
    "        val_f1_max=0.0\n",
    "        epochs=[]\n",
    "        lossesT=[]\n",
    "        lossesV=[]\n",
    "\n",
    "        for epoch in range(max_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch+1,max_epochs))\n",
    "            print('-'*10)\n",
    "            \n",
    "            since=time.time()\n",
    "            train_metrics=defaultdict(float)\n",
    "            total_loss=0\n",
    "            running_corrects=0\n",
    "            num_steps=0\n",
    "            \n",
    "            all_labels_d = torch.tensor([], dtype=torch.long).to(device)\n",
    "            all_predictions_d = torch.tensor([], dtype=torch.long).to(device)\n",
    "            all_predictions_probabilities_d = torch.tensor([], dtype=torch.float).to(device)\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "            #Training\n",
    "            for image, labels in self.training_generator:\n",
    "                #Transfer to GPU:\n",
    "                \n",
    "                image, labels = image.to(device, dtype=torch.float32), labels.to(device)\n",
    "                outputs = model(image)\n",
    "                predicted_probability, predicted  = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "              \n",
    "                num_steps+=image.size(0)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss+=loss.item()*image.size(0)\n",
    "           \n",
    "                running_corrects += torch.sum(predicted == labels.data)\n",
    "                all_labels_d = torch.cat((all_labels_d, labels), 0)\n",
    "                all_predictions_d = torch.cat((all_predictions_d, predicted), 0)\n",
    "                all_predictions_probabilities_d = torch.cat((all_predictions_probabilities_d, predicted_probability), 0)\n",
    "                \n",
    "                \n",
    "            y_true = all_labels_d.cpu()\n",
    "            y_predicted = all_predictions_d.cpu()  # to('cpu')\n",
    "            valset_predicted_probabilites = all_predictions_probabilities_d.cpu()  # to('cpu')\n",
    "            \n",
    "            \n",
    "            #############################\n",
    "            # Standard metrics \n",
    "            #############################\n",
    "        \n",
    "            train_micro_precision=mtc.precision_score(y_true, y_predicted, average=\"micro\")     \n",
    "            train_micro_recall=mtc.recall_score(y_true, y_predicted, average=\"micro\")\n",
    "            train_micro_f1=mtc.f1_score(y_true, y_predicted, average=\"micro\")  \n",
    "        \n",
    "            train_macro_precision=mtc.precision_score(y_true, y_predicted, average=\"macro\")     \n",
    "            train_macro_recall=mtc.recall_score(y_true, y_predicted, average=\"macro\")\n",
    "            train_macro_f1=mtc.f1_score(y_true, y_predicted, average=\"macro\")  \n",
    "        \n",
    "            train_mcc=mtc.matthews_corrcoef(y_true, y_predicted)\n",
    "             \n",
    "            \n",
    "            train_metrics['loss']=total_loss/num_steps\n",
    "        \n",
    "            train_metrics['micro_precision']=train_micro_precision\n",
    "            train_metrics['micro_recall']=train_micro_recall\n",
    "            train_metrics['micro_f1']=train_micro_f1\n",
    "            train_metrics['macro_precision']=train_macro_precision\n",
    "            train_metrics['macro_recall']=train_macro_recall\n",
    "            train_metrics['macro_f1']=train_macro_f1\n",
    "            train_metrics['mcc']=train_mcc\n",
    "            \n",
    "            print('Training...')\n",
    "            print('Train_loss:{:.3f}'.format(total_loss/num_steps))\n",
    "           \n",
    "            \n",
    "            print_metrics(train_metrics,num_steps)\n",
    "\n",
    "            ############################\n",
    "            # Validation\n",
    "            ############################\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss, val_metrics, val_num_steps=validate_net(model,self.validation_generator,device,criterion)\n",
    "                \n",
    "            scheduler.step(val_loss)\n",
    "            epochs.append(epoch)\n",
    "            lossesT.append(total_loss/num_steps)\n",
    "            lossesV.append(val_loss)\n",
    "            \n",
    "            print('.'*5)\n",
    "            print('Validating...')\n",
    "            print('val_loss:{:.3f}'.format(val_loss))\n",
    "        \n",
    "            print_metrics(val_metrics,val_num_steps)\n",
    "\n",
    "\n",
    "            ##################################################################\n",
    "            # Writing epoch-wise training and validation results to a csv file \n",
    "            ##################################################################\n",
    "\n",
    "            key_name=['Epoch','Train_loss','Train_micro_precision','Train_micro_recall','Train_micro_f1','Train_macro_precision','Train_macro_recall','Train_macro_f1','Train_mcc','Val_loss','Val_micro_precision','Val_micro_recall','Val_micro_f1','Val_macro_precision','Val_macro_recall','Val_macro_f1','Val_mcc']\n",
    "            train_list=[]\n",
    "            train_list.append(epoch)\n",
    "\n",
    "            try:\n",
    "\n",
    "                with open(filename+str('.csv'), 'a',newline=\"\") as f:\n",
    "                    wr = csv.writer(f,delimiter=\",\")\n",
    "                    if epoch==0:\n",
    "                        wr.writerow(key_name)\n",
    "\n",
    "                    for k, vl in train_metrics.items():\n",
    "                        train_list.append(vl)\n",
    "\n",
    "                    train_list.append(val_loss)\n",
    "\n",
    "                    for k, vl in val_metrics.items():\n",
    "                        train_list.append(vl)\n",
    "                    zip(train_list)\n",
    "                    wr.writerow(train_list)\n",
    "\n",
    "\n",
    "            except IOError:\n",
    "                print(\"I/O Error\")\n",
    "\n",
    "            \n",
    "            ##############################\n",
    "            # Saving best model \n",
    "            ##############################\n",
    "            \n",
    "            if val_metrics['micro_f1']>=val_f1_max:\n",
    "                print('val micro f1 increased ({:.6f}-->{:.6f}).Saving model'.format(val_f1_max,val_metrics['micro_f1']))\n",
    "                \n",
    "                torch.save({'epoch':epoch+1,\n",
    "                            'model_state_dict':model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'scheduler': scheduler.state_dict(), \n",
    "                            'loss':val_loss},model_path+f'/C_{epoch+1}_{batch_size}.pth')\n",
    "                best_model_path=model_path+f'/C_{epoch+1}_{batch_size}.pth'\n",
    "               \n",
    "                val_f1_max=val_metrics['micro_f1']\n",
    "                \n",
    "\n",
    "            print('-'*10)\n",
    "       \n",
    "        time_elapsed=time.time()-since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        \n",
    "        training_curve(epochs,lossesT,lossesV)\n",
    "        epochs.clear()\n",
    "        lossesT.clear()\n",
    "        lossesV.clear()\n",
    "        \n",
    "\n",
    "        ############################\n",
    "        #         Test\n",
    "        ############################\n",
    "        test_list=[]\n",
    "        print('Best model path:{}'.format(best_model_path))\n",
    "        best_model=torchvision.models.densenet121(weights=False).to(device)\n",
    "        \n",
    "        n_inputs = best_model.classifier.in_features\n",
    "        best_model.classifier = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, n_classes),               \n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    " \n",
    "        checkpoint=torch.load(best_model_path,map_location=device)   # loading best model\n",
    "        best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model.to(device)\n",
    "        best_model.eval()\n",
    "        with torch.no_grad():\n",
    "       \t       test_loss, test_metrics, test_num_steps=test_net(best_model,self.test_generator,device,criterion)\n",
    "\n",
    "        \n",
    "        print_metrics(test_metrics,test_num_steps)\n",
    "        test_list.append(test_loss)\n",
    "     \n",
    "\n",
    "        for k, vl in test_metrics.items():      \n",
    "            test_list.append(vl)              # append metrics results in a list\n",
    "  \n",
    "  \n",
    "  \n",
    "        ##################################################################\n",
    "        # Writing test results to a csv file \n",
    "        ##################################################################\n",
    "\n",
    "        key_name=['Test_loss','Test_micro_precision','Test_micro_recall','Test_micro_f1','Test_macro_precision','Test_macro_recall','Test_macro_f1','Test_mcc']\n",
    "        try:\n",
    "\n",
    "                with open(filename+str('.csv'), 'a',newline=\"\") as f:\n",
    "                    wr = csv.writer(f,delimiter=\",\")\n",
    "                    wr.writerow(key_name)\n",
    "                    zip(test_list)\n",
    "                    wr.writerow(test_list) \n",
    "                    wr.writerow(\"\") \n",
    "        except IOError:\n",
    "                print(\"I/O Error\")  \n",
    "        return val_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "435934c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device: cpu\n",
      "INFO: Starting training:\n",
      "             Epochs: 30\n",
      "             Batch Size: 32\n",
      "             Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training set images:1062\n",
      "Number of Validation set images:265\n",
      "Number of Test set images:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\User1/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n",
      "100%|| 30.8M/30.8M [00:00<00:00, 74.8MB/s]\n",
      "C:\\Users\\User1\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.110\n",
      "loss:0.109836,micro_precision:0.967043,micro_recall:0.967043,micro_f1:0.967043,macro_precision:0.967992,macro_recall:0.966961,macro_f1:0.967022,mcc:0.934953\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.014\n",
      "micro_precision:0.996226,micro_recall:0.996226,micro_f1:0.996226,macro_precision:0.996241,macro_recall:0.996241,macro_f1:0.996226,mcc:0.992481\n",
      "val micro f1 increased (0.000000-->0.996226).Saving model\n",
      "----------\n",
      "Epoch 2/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.014\n",
      "loss:0.013551,micro_precision:0.996234,micro_recall:0.996234,micro_f1:0.996234,macro_precision:0.996234,macro_recall:0.996241,macro_f1:0.996234,mcc:0.992474\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.129\n",
      "micro_precision:0.954717,micro_recall:0.954717,micro_f1:0.954717,macro_precision:0.958333,macro_recall:0.954887,macro_f1:0.954639,mcc:0.913214\n",
      "----------\n",
      "Epoch 3/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.005\n",
      "loss:0.005000,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.007\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (0.996226-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 4/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.002\n",
      "loss:0.001681,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.015\n",
      "micro_precision:0.992453,micro_recall:0.992453,micro_f1:0.992453,macro_precision:0.992537,macro_recall:0.992481,macro_f1:0.992453,mcc:0.985019\n",
      "----------\n",
      "Epoch 5/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.003\n",
      "loss:0.002540,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.006\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 6/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.002\n",
      "loss:0.002159,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.005\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 7/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.001\n",
      "loss:0.001136,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.004\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 8/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.001\n",
      "loss:0.001028,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.005\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 9/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.011\n",
      "loss:0.011045,micro_precision:0.997175,micro_recall:0.997175,micro_f1:0.997175,macro_precision:0.997173,macro_recall:0.997179,macro_f1:0.997175,mcc:0.994352\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 10/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.008\n",
      "loss:0.008367,micro_precision:0.999058,micro_recall:0.999058,micro_f1:0.999058,macro_precision:0.999064,macro_recall:0.999055,macro_f1:0.999058,mcc:0.998118\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.008\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 11/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.005\n",
      "loss:0.005119,micro_precision:0.999058,micro_recall:0.999058,micro_f1:0.999058,macro_precision:0.999064,macro_recall:0.999055,macro_f1:0.999058,mcc:0.998118\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.008\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 12/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.001\n",
      "loss:0.000891,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.004\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 13/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.001\n",
      "loss:0.000512,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.003\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 14/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000461,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 15/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000375,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 16/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000283,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 17/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000325,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 18/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000314,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 19/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000400,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 20/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000347,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.003\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 21/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000346,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 22/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000335,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 23/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.001\n",
      "loss:0.000601,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 24/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000402,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 25/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000229,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 26/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000289,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 27/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000210,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 28/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000466,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.003\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 29/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000405,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.003\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 30/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.000\n",
      "loss:0.000316,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.004\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "43m 28s\n",
      "Best model path:./checkpoints_30_32_0001//C_30_32.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 443 test images: 100.000000 %\n",
      "[[222   0]\n",
      " [  0 221]]\n",
      "taking class names to plot CM\n",
      "Generating confution matrix\n",
      "Confusion matrix, without normalization\n",
      "[[222   0]\n",
      " [  0 221]]\n",
      "Finished confusion matrix drawing...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        esca       1.00      1.00      1.00       222\n",
      "     healthy       1.00      1.00      1.00       221\n",
      "\n",
      "    accuracy                           1.00       443\n",
      "   macro avg       1.00      1.00      1.00       443\n",
      "weighted avg       1.00      1.00      1.00       443\n",
      "\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(float,\n",
       "             {'micro_precision': 1.0,\n",
       "              'micro_recall': 1.0,\n",
       "              'micro_f1': 1.0,\n",
       "              'macro_precision': 1.0,\n",
       "              'macro_recall': 1.0,\n",
       "              'macro_f1': 1.0,\n",
       "              'mcc': 1.0}),\n",
       " defaultdict(float,\n",
       "             {'micro_precision': 1.0,\n",
       "              'micro_recall': 1.0,\n",
       "              'micro_f1': 1.0,\n",
       "              'macro_precision': 1.0,\n",
       "              'macro_recall': 1.0,\n",
       "              'macro_f1': 1.0,\n",
       "              'mcc': 1.0}))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logging.info(f'Using device: {device}')\n",
    "logging.info(f'''Starting training:\n",
    "             Epochs: {max_epochs}\n",
    "             Batch Size: {batch_size}\n",
    "             Learning Rate: {lr}''')\n",
    "t=train()\n",
    "t.train_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62cea4-6dca-40e9-abfc-84bbdb1eff73",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5484e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "047dd76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to the input size of DenseNet-121\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eee0bd2a-a3e5-4bf9-afbe-63256f98219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your single image\n",
    "PATH_DATASET = './../data_processed'\n",
    "\n",
    "image_path = os.path.join(PATH_DATASET, 'test','healthy','healthy_662_cam3.jpg')  # Replace 'path_to_your_image.jpg' with the path to your image\n",
    "image = Image.open(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53fd2781-fb87-4da6-a34f-6b07a3d16e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations\n",
    "input_image = transform(image).unsqueeze(0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f92069c-ffa2-45ad-a498-a541b29d1d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = torchvision.models.densenet121(pretrained=True)  # Assuming you want to use the pre-trained weights\n",
    "model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb0d0020-1c03-441c-ba29-fbc17d9d0b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=2, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "############################\n",
    "#         Inference\n",
    "############################\n",
    "test_model_path = \"./checkpoints_30_32_0001//C_30_32.pth\"\n",
    "n_classes = 2\n",
    "\n",
    "test_model=torchvision.models.densenet121(weights=False).to(device)\n",
    "\n",
    "n_inputs = test_model.classifier.in_features\n",
    "test_model.classifier = nn.Sequential(\n",
    "              nn.Linear(n_inputs, n_classes),               \n",
    "              nn.LogSoftmax(dim=1))\n",
    "\n",
    "\n",
    "checkpoint=torch.load(test_model_path,map_location=device)   # loading best model\n",
    "test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "test_model.to(device)\n",
    "test_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddeff773-1c8e-4f91-9ef0-4259a91064e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: healthy\n"
     ]
    }
   ],
   "source": [
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = test_model(input_image)\n",
    "\n",
    "    # Get the predicted class index\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    predicted_class_index = predicted.item()\n",
    "    \n",
    "    # Interpret the results (assuming you have a class label mapping)\n",
    "    class_labels = ['healthy','esca' ]  # Replace with your actual class labels\n",
    "    predicted_class_label = class_labels[predicted_class_index]\n",
    "    print('Predicted class:', predicted_class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ccf45bd-3c0b-4dcf-a19a-e17c7f7a51d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: healthy\n"
     ]
    }
   ],
   "source": [
    "print('Predicted class:', predicted_class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022aca37-e139-48a9-b37a-bf5e8f37154e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923137f4-54b5-4dea-a6c1-36ec4c0a106f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
