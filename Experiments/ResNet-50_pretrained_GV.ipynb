{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe063d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from Validate import validate_net\n",
    "from Test import test_net\n",
    "from misc import print_metrics, training_curve \n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import logging\n",
    "import csv\n",
    "from torchvision import transforms, datasets, models\n",
    "import sklearn.metrics as mtc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca7f6e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################\n",
    "# Checking if GPU is used\n",
    "###########################\n",
    "\n",
    "use_cuda=torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "device=torch.device(\"cuda:0\" if use_cuda else \"mps\" if use_mps else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc82d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Setting basic parameters for the model\n",
    "########################################           \n",
    "         \n",
    "batch_size=32\n",
    "max_epochs=30\n",
    "lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76bada85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of dataset\n",
    "dir_original = \"./../GrapevineDS\"\n",
    "\n",
    "# name of new dataset\n",
    "dir_processed = \"./../data_processed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b121c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_samples:  ['train', 'validation', 'test'] \n",
      "\n",
      "class:  ['esca' 'healthy'] \n",
      "\n",
      "number of images for class:  [888 882] \n",
      "\n",
      "split of dataset: \n",
      "  [[533 133 222]\n",
      " [529 132 220]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(dir_original)\n",
    "\n",
    "set_samples = ['train', 'validation', 'test']\n",
    "print(\"set_samples: \", set_samples, \"\\n\")\n",
    "\n",
    "CLASS_NAMES = np.array([item.name for item in sorted(data_dir.glob('*'))])\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "print(\"class: \", CLASS_NAMES, \"\\n\")\n",
    "\n",
    "N_IMAGES = np.array([len(list(data_dir.glob(item.name+'/*.jpg'))) for item in sorted(data_dir.glob('*'))])\t\t\t# number of images for class\n",
    "print(\"number of images for class: \", N_IMAGES, \"\\n\")\n",
    "\n",
    "N_samples = np.array([(int(np.around(n*60/100)), int(np.around(n*15/100)), int(np.around(n*25/100))) for n in N_IMAGES])\t# number of images for set (train,validation,test)\n",
    "print(\"split of dataset: \\n \", N_samples, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bbedb5",
   "metadata": {},
   "source": [
    "### Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2a19d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of new images\n",
    "# size of new images\n",
    "size = 1280, 720\n",
    "\n",
    "try:\n",
    "    # Check if dir_processed exists and is a directory\n",
    "    if not os.path.isdir(dir_processed):\n",
    "        # If it's not a directory, create it\n",
    "        os.makedirs(dir_processed)\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "\n",
    "# Now create subdirectories for sets and classes\n",
    "for set_tag in set_samples:\n",
    "    os.makedirs(os.path.join(dir_processed, set_tag),exist_ok=True)\n",
    "    for class_name in CLASS_NAMES:\n",
    "        os.makedirs(os.path.join(dir_processed, set_tag, class_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9987dea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split dataset.....\n",
      "class name:  esca\n",
      "image:  0\n",
      "image:  1\n",
      "image:  2\n",
      "image:  3\n",
      "image:  4\n",
      "image:  5\n",
      "image:  6\n",
      "image:  7\n",
      "image:  8\n",
      "image:  9\n",
      "image:  10\n",
      "image:  11\n",
      "image:  12\n",
      "image:  13\n",
      "image:  14\n",
      "image:  15\n",
      "image:  16\n",
      "image:  17\n",
      "image:  18\n",
      "image:  19\n",
      "image:  20\n",
      "image:  21\n",
      "image:  22\n",
      "image:  23\n",
      "image:  24\n",
      "image:  25\n",
      "image:  26\n",
      "image:  27\n",
      "image:  28\n",
      "image:  29\n",
      "image:  30\n",
      "image:  31\n",
      "image:  32\n",
      "image:  33\n",
      "image:  34\n",
      "image:  35\n",
      "image:  36\n",
      "image:  37\n",
      "image:  38\n",
      "image:  39\n",
      "image:  40\n",
      "image:  41\n",
      "image:  42\n",
      "image:  43\n",
      "image:  44\n",
      "image:  45\n",
      "image:  46\n",
      "image:  47\n",
      "image:  48\n",
      "image:  49\n",
      "image:  50\n",
      "image:  51\n",
      "image:  52\n",
      "image:  53\n",
      "image:  54\n",
      "image:  55\n",
      "image:  56\n",
      "image:  57\n",
      "image:  58\n",
      "image:  59\n",
      "image:  60\n",
      "image:  61\n",
      "image:  62\n",
      "image:  63\n",
      "image:  64\n",
      "image:  65\n",
      "image:  66\n",
      "image:  67\n",
      "image:  68\n",
      "image:  69\n",
      "image:  70\n",
      "image:  71\n",
      "image:  72\n",
      "image:  73\n",
      "image:  74\n",
      "image:  75\n",
      "image:  76\n",
      "image:  77\n",
      "image:  78\n",
      "image:  79\n",
      "image:  80\n",
      "image:  81\n",
      "image:  82\n",
      "image:  83\n",
      "image:  84\n",
      "image:  85\n",
      "image:  86\n",
      "image:  87\n",
      "image:  88\n",
      "image:  89\n",
      "image:  90\n",
      "image:  91\n",
      "image:  92\n",
      "image:  93\n",
      "image:  94\n",
      "image:  95\n",
      "image:  96\n",
      "image:  97\n",
      "image:  98\n",
      "image:  99\n",
      "image:  100\n",
      "image:  101\n",
      "image:  102\n",
      "image:  103\n",
      "image:  104\n",
      "image:  105\n",
      "image:  106\n",
      "image:  107\n",
      "image:  108\n",
      "image:  109\n",
      "image:  110\n",
      "image:  111\n",
      "image:  112\n",
      "image:  113\n",
      "image:  114\n",
      "image:  115\n",
      "image:  116\n",
      "image:  117\n",
      "image:  118\n",
      "image:  119\n",
      "image:  120\n",
      "image:  121\n",
      "image:  122\n",
      "image:  123\n",
      "image:  124\n",
      "image:  125\n",
      "image:  126\n",
      "image:  127\n",
      "image:  128\n",
      "image:  129\n",
      "image:  130\n",
      "image:  131\n",
      "image:  132\n",
      "image:  133\n",
      "image:  134\n",
      "image:  135\n",
      "image:  136\n",
      "image:  137\n",
      "image:  138\n",
      "image:  139\n",
      "image:  140\n",
      "image:  141\n",
      "image:  142\n",
      "image:  143\n",
      "image:  144\n",
      "image:  145\n",
      "image:  146\n",
      "image:  147\n",
      "image:  148\n",
      "image:  149\n",
      "image:  150\n",
      "image:  151\n",
      "image:  152\n",
      "image:  153\n",
      "image:  154\n",
      "image:  155\n",
      "image:  156\n",
      "image:  157\n",
      "image:  158\n",
      "image:  159\n",
      "image:  160\n",
      "image:  161\n",
      "image:  162\n",
      "image:  163\n",
      "image:  164\n",
      "image:  165\n",
      "image:  166\n",
      "image:  167\n",
      "image:  168\n",
      "image:  169\n",
      "image:  170\n",
      "image:  171\n",
      "image:  172\n",
      "image:  173\n",
      "image:  174\n",
      "image:  175\n",
      "image:  176\n",
      "image:  177\n",
      "image:  178\n",
      "image:  179\n",
      "image:  180\n",
      "image:  181\n",
      "image:  182\n",
      "image:  183\n",
      "image:  184\n",
      "image:  185\n",
      "image:  186\n",
      "image:  187\n",
      "image:  188\n",
      "image:  189\n",
      "image:  190\n",
      "image:  191\n",
      "image:  192\n",
      "image:  193\n",
      "image:  194\n",
      "image:  195\n",
      "image:  196\n",
      "image:  197\n",
      "image:  198\n",
      "image:  199\n",
      "image:  200\n",
      "image:  201\n",
      "image:  202\n",
      "image:  203\n",
      "image:  204\n",
      "image:  205\n",
      "image:  206\n",
      "image:  207\n",
      "image:  208\n",
      "image:  209\n",
      "image:  210\n",
      "image:  211\n",
      "image:  212\n",
      "image:  213\n",
      "image:  214\n",
      "image:  215\n",
      "image:  216\n",
      "image:  217\n",
      "image:  218\n",
      "image:  219\n",
      "image:  220\n",
      "image:  221\n",
      "image:  222\n",
      "image:  223\n",
      "image:  224\n",
      "image:  225\n",
      "image:  226\n",
      "image:  227\n",
      "image:  228\n",
      "image:  229\n",
      "image:  230\n",
      "image:  231\n",
      "image:  232\n",
      "image:  233\n",
      "image:  234\n",
      "image:  235\n",
      "image:  236\n",
      "image:  237\n",
      "image:  238\n",
      "image:  239\n",
      "image:  240\n",
      "image:  241\n",
      "image:  242\n",
      "image:  243\n",
      "image:  244\n",
      "image:  245\n",
      "image:  246\n",
      "image:  247\n",
      "image:  248\n",
      "image:  249\n",
      "image:  250\n",
      "image:  251\n",
      "image:  252\n",
      "image:  253\n",
      "image:  254\n",
      "image:  255\n",
      "image:  256\n",
      "image:  257\n",
      "image:  258\n",
      "image:  259\n",
      "image:  260\n",
      "image:  261\n",
      "image:  262\n",
      "image:  263\n",
      "image:  264\n",
      "image:  265\n",
      "image:  266\n",
      "image:  267\n",
      "image:  268\n",
      "image:  269\n",
      "image:  270\n",
      "image:  271\n",
      "image:  272\n",
      "image:  273\n",
      "image:  274\n",
      "image:  275\n",
      "image:  276\n",
      "image:  277\n",
      "image:  278\n",
      "image:  279\n",
      "image:  280\n",
      "image:  281\n",
      "image:  282\n",
      "image:  283\n",
      "image:  284\n",
      "image:  285\n",
      "image:  286\n",
      "image:  287\n",
      "image:  288\n",
      "image:  289\n",
      "image:  290\n",
      "image:  291\n",
      "image:  292\n",
      "image:  293\n",
      "image:  294\n",
      "image:  295\n",
      "image:  296\n",
      "image:  297\n",
      "image:  298\n",
      "image:  299\n",
      "image:  300\n",
      "image:  301\n",
      "image:  302\n",
      "image:  303\n",
      "image:  304\n",
      "image:  305\n",
      "image:  306\n",
      "image:  307\n",
      "image:  308\n",
      "image:  309\n",
      "image:  310\n",
      "image:  311\n",
      "image:  312\n",
      "image:  313\n",
      "image:  314\n",
      "image:  315\n",
      "image:  316\n",
      "image:  317\n",
      "image:  318\n",
      "image:  319\n",
      "image:  320\n",
      "image:  321\n",
      "image:  322\n",
      "image:  323\n",
      "image:  324\n",
      "image:  325\n",
      "image:  326\n",
      "image:  327\n",
      "image:  328\n",
      "image:  329\n",
      "image:  330\n",
      "image:  331\n",
      "image:  332\n",
      "image:  333\n",
      "image:  334\n",
      "image:  335\n",
      "image:  336\n",
      "image:  337\n",
      "image:  338\n",
      "image:  339\n",
      "image:  340\n",
      "image:  341\n",
      "image:  342\n",
      "image:  343\n",
      "image:  344\n",
      "image:  345\n",
      "image:  346\n",
      "image:  347\n",
      "image:  348\n",
      "image:  349\n",
      "image:  350\n",
      "image:  351\n",
      "image:  352\n",
      "image:  353\n",
      "image:  354\n",
      "image:  355\n",
      "image:  356\n",
      "image:  357\n",
      "image:  358\n",
      "image:  359\n",
      "image:  360\n",
      "image:  361\n",
      "image:  362\n",
      "image:  363\n",
      "image:  364\n",
      "image:  365\n",
      "image:  366\n",
      "image:  367\n",
      "image:  368\n",
      "image:  369\n",
      "image:  370\n",
      "image:  371\n",
      "image:  372\n",
      "image:  373\n",
      "image:  374\n",
      "image:  375\n",
      "image:  376\n",
      "image:  377\n",
      "image:  378\n",
      "image:  379\n",
      "image:  380\n",
      "image:  381\n",
      "image:  382\n",
      "image:  383\n",
      "image:  384\n",
      "image:  385\n",
      "image:  386\n",
      "image:  387\n",
      "image:  388\n",
      "image:  389\n",
      "image:  390\n",
      "image:  391\n",
      "image:  392\n",
      "image:  393\n",
      "image:  394\n",
      "image:  395\n",
      "image:  396\n",
      "image:  397\n",
      "image:  398\n",
      "image:  399\n",
      "image:  400\n",
      "image:  401\n",
      "image:  402\n",
      "image:  403\n",
      "image:  404\n",
      "image:  405\n",
      "image:  406\n",
      "image:  407\n",
      "image:  408\n",
      "image:  409\n",
      "image:  410\n",
      "image:  411\n",
      "image:  412\n",
      "image:  413\n",
      "image:  414\n",
      "image:  415\n",
      "image:  416\n",
      "image:  417\n",
      "image:  418\n",
      "image:  419\n",
      "image:  420\n",
      "image:  421\n",
      "image:  422\n",
      "image:  423\n",
      "image:  424\n",
      "image:  425\n",
      "image:  426\n",
      "image:  427\n",
      "image:  428\n",
      "image:  429\n",
      "image:  430\n",
      "image:  431\n",
      "image:  432\n",
      "image:  433\n",
      "image:  434\n",
      "image:  435\n",
      "image:  436\n",
      "image:  437\n",
      "image:  438\n",
      "image:  439\n",
      "image:  440\n",
      "image:  441\n",
      "image:  442\n",
      "image:  443\n",
      "image:  444\n",
      "image:  445\n",
      "image:  446\n",
      "image:  447\n",
      "image:  448\n",
      "image:  449\n",
      "image:  450\n",
      "image:  451\n",
      "image:  452\n",
      "image:  453\n",
      "image:  454\n",
      "image:  455\n",
      "image:  456\n",
      "image:  457\n",
      "image:  458\n",
      "image:  459\n",
      "image:  460\n",
      "image:  461\n",
      "image:  462\n",
      "image:  463\n",
      "image:  464\n",
      "image:  465\n",
      "image:  466\n",
      "image:  467\n",
      "image:  468\n",
      "image:  469\n",
      "image:  470\n",
      "image:  471\n",
      "image:  472\n",
      "image:  473\n",
      "image:  474\n",
      "image:  475\n",
      "image:  476\n",
      "image:  477\n",
      "image:  478\n",
      "image:  479\n",
      "image:  480\n",
      "image:  481\n",
      "image:  482\n",
      "image:  483\n",
      "image:  484\n",
      "image:  485\n",
      "image:  486\n",
      "image:  487\n",
      "image:  488\n",
      "image:  489\n",
      "image:  490\n",
      "image:  491\n",
      "image:  492\n",
      "image:  493\n",
      "image:  494\n",
      "image:  495\n",
      "image:  496\n",
      "image:  497\n",
      "image:  498\n",
      "image:  499\n",
      "image:  500\n",
      "image:  501\n",
      "image:  502\n",
      "image:  503\n",
      "image:  504\n",
      "image:  505\n",
      "image:  506\n",
      "image:  507\n",
      "image:  508\n",
      "image:  509\n",
      "image:  510\n",
      "image:  511\n",
      "image:  512\n",
      "image:  513\n",
      "image:  514\n",
      "image:  515\n",
      "image:  516\n",
      "image:  517\n",
      "image:  518\n",
      "image:  519\n",
      "image:  520\n",
      "image:  521\n",
      "image:  522\n",
      "image:  523\n",
      "image:  524\n",
      "image:  525\n",
      "image:  526\n",
      "image:  527\n",
      "image:  528\n",
      "image:  529\n",
      "image:  530\n",
      "image:  531\n",
      "image:  532\n",
      "image:  533\n",
      "updating k:  0\n",
      "3\n",
      "image:  534\n",
      "image:  535\n",
      "image:  536\n",
      "image:  537\n",
      "image:  538\n",
      "image:  539\n",
      "image:  540\n",
      "image:  541\n",
      "image:  542\n",
      "image:  543\n",
      "image:  544\n",
      "image:  545\n",
      "image:  546\n",
      "image:  547\n",
      "image:  548\n",
      "image:  549\n",
      "image:  550\n",
      "image:  551\n",
      "image:  552\n",
      "image:  553\n",
      "image:  554\n",
      "image:  555\n",
      "image:  556\n",
      "image:  557\n",
      "image:  558\n",
      "image:  559\n",
      "image:  560\n",
      "image:  561\n",
      "image:  562\n",
      "image:  563\n",
      "image:  564\n",
      "image:  565\n",
      "image:  566\n",
      "image:  567\n",
      "image:  568\n",
      "image:  569\n",
      "image:  570\n",
      "image:  571\n",
      "image:  572\n",
      "image:  573\n",
      "image:  574\n",
      "image:  575\n",
      "image:  576\n",
      "image:  577\n",
      "image:  578\n",
      "image:  579\n",
      "image:  580\n",
      "image:  581\n",
      "image:  582\n",
      "image:  583\n",
      "image:  584\n",
      "image:  585\n",
      "image:  586\n",
      "image:  587\n",
      "image:  588\n",
      "image:  589\n",
      "image:  590\n",
      "image:  591\n",
      "image:  592\n",
      "image:  593\n",
      "image:  594\n",
      "image:  595\n",
      "image:  596\n",
      "image:  597\n",
      "image:  598\n",
      "image:  599\n",
      "image:  600\n",
      "image:  601\n",
      "image:  602\n",
      "image:  603\n",
      "image:  604\n",
      "image:  605\n",
      "image:  606\n",
      "image:  607\n",
      "image:  608\n",
      "image:  609\n",
      "image:  610\n",
      "image:  611\n",
      "image:  612\n",
      "image:  613\n",
      "image:  614\n",
      "image:  615\n",
      "image:  616\n",
      "image:  617\n",
      "image:  618\n",
      "image:  619\n",
      "image:  620\n",
      "image:  621\n",
      "image:  622\n",
      "image:  623\n",
      "image:  624\n",
      "image:  625\n",
      "image:  626\n",
      "image:  627\n",
      "image:  628\n",
      "image:  629\n",
      "image:  630\n",
      "image:  631\n",
      "image:  632\n",
      "image:  633\n",
      "image:  634\n",
      "image:  635\n",
      "image:  636\n",
      "image:  637\n",
      "image:  638\n",
      "image:  639\n",
      "image:  640\n",
      "image:  641\n",
      "image:  642\n",
      "image:  643\n",
      "image:  644\n",
      "image:  645\n",
      "image:  646\n",
      "image:  647\n",
      "image:  648\n",
      "image:  649\n",
      "image:  650\n",
      "image:  651\n",
      "image:  652\n",
      "image:  653\n",
      "image:  654\n",
      "image:  655\n",
      "image:  656\n",
      "image:  657\n",
      "image:  658\n",
      "image:  659\n",
      "image:  660\n",
      "image:  661\n",
      "image:  662\n",
      "image:  663\n",
      "image:  664\n",
      "image:  665\n",
      "image:  666\n",
      "updating k:  1\n",
      "3\n",
      "image:  667\n",
      "image:  668\n",
      "image:  669\n",
      "image:  670\n",
      "image:  671\n",
      "image:  672\n",
      "image:  673\n",
      "image:  674\n",
      "image:  675\n",
      "image:  676\n",
      "image:  677\n",
      "image:  678\n",
      "image:  679\n",
      "image:  680\n",
      "image:  681\n",
      "image:  682\n",
      "image:  683\n",
      "image:  684\n",
      "image:  685\n",
      "image:  686\n",
      "image:  687\n",
      "image:  688\n",
      "image:  689\n",
      "image:  690\n",
      "image:  691\n",
      "image:  692\n",
      "image:  693\n",
      "image:  694\n",
      "image:  695\n",
      "image:  696\n",
      "image:  697\n",
      "image:  698\n",
      "image:  699\n",
      "image:  700\n",
      "image:  701\n",
      "image:  702\n",
      "image:  703\n",
      "image:  704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image:  705\n",
      "image:  706\n",
      "image:  707\n",
      "image:  708\n",
      "image:  709\n",
      "image:  710\n",
      "image:  711\n",
      "image:  712\n",
      "image:  713\n",
      "image:  714\n",
      "image:  715\n",
      "image:  716\n",
      "image:  717\n",
      "image:  718\n",
      "image:  719\n",
      "image:  720\n",
      "image:  721\n",
      "image:  722\n",
      "image:  723\n",
      "image:  724\n",
      "image:  725\n",
      "image:  726\n",
      "image:  727\n",
      "image:  728\n",
      "image:  729\n",
      "image:  730\n",
      "image:  731\n",
      "image:  732\n",
      "image:  733\n",
      "image:  734\n",
      "image:  735\n",
      "image:  736\n",
      "image:  737\n",
      "image:  738\n",
      "image:  739\n",
      "image:  740\n",
      "image:  741\n",
      "image:  742\n",
      "image:  743\n",
      "image:  744\n",
      "image:  745\n",
      "image:  746\n",
      "image:  747\n",
      "image:  748\n",
      "image:  749\n",
      "image:  750\n",
      "image:  751\n",
      "image:  752\n",
      "image:  753\n",
      "image:  754\n",
      "image:  755\n",
      "image:  756\n",
      "image:  757\n",
      "image:  758\n",
      "image:  759\n",
      "image:  760\n",
      "image:  761\n",
      "image:  762\n",
      "image:  763\n",
      "image:  764\n",
      "image:  765\n",
      "image:  766\n",
      "image:  767\n",
      "image:  768\n",
      "image:  769\n",
      "image:  770\n",
      "image:  771\n",
      "image:  772\n",
      "image:  773\n",
      "image:  774\n",
      "image:  775\n",
      "image:  776\n",
      "image:  777\n",
      "image:  778\n",
      "image:  779\n",
      "image:  780\n",
      "image:  781\n",
      "image:  782\n",
      "image:  783\n",
      "image:  784\n",
      "image:  785\n",
      "image:  786\n",
      "image:  787\n",
      "image:  788\n",
      "image:  789\n",
      "image:  790\n",
      "image:  791\n",
      "image:  792\n",
      "image:  793\n",
      "image:  794\n",
      "image:  795\n",
      "image:  796\n",
      "image:  797\n",
      "image:  798\n",
      "image:  799\n",
      "image:  800\n",
      "image:  801\n",
      "image:  802\n",
      "image:  803\n",
      "image:  804\n",
      "image:  805\n",
      "image:  806\n",
      "image:  807\n",
      "image:  808\n",
      "image:  809\n",
      "image:  810\n",
      "image:  811\n",
      "image:  812\n",
      "image:  813\n",
      "image:  814\n",
      "image:  815\n",
      "image:  816\n",
      "image:  817\n",
      "image:  818\n",
      "image:  819\n",
      "image:  820\n",
      "image:  821\n",
      "image:  822\n",
      "image:  823\n",
      "image:  824\n",
      "image:  825\n",
      "image:  826\n",
      "image:  827\n",
      "image:  828\n",
      "image:  829\n",
      "image:  830\n",
      "image:  831\n",
      "image:  832\n",
      "image:  833\n",
      "image:  834\n",
      "image:  835\n",
      "image:  836\n",
      "image:  837\n",
      "image:  838\n",
      "image:  839\n",
      "image:  840\n",
      "image:  841\n",
      "image:  842\n",
      "image:  843\n",
      "image:  844\n",
      "image:  845\n",
      "image:  846\n",
      "image:  847\n",
      "image:  848\n",
      "image:  849\n",
      "image:  850\n",
      "image:  851\n",
      "image:  852\n",
      "image:  853\n",
      "image:  854\n",
      "image:  855\n",
      "image:  856\n",
      "image:  857\n",
      "image:  858\n",
      "image:  859\n",
      "image:  860\n",
      "image:  861\n",
      "image:  862\n",
      "image:  863\n",
      "image:  864\n",
      "image:  865\n",
      "image:  866\n",
      "image:  867\n",
      "image:  868\n",
      "image:  869\n",
      "image:  870\n",
      "image:  871\n",
      "image:  872\n",
      "image:  873\n",
      "image:  874\n",
      "image:  875\n",
      "image:  876\n",
      "image:  877\n",
      "image:  878\n",
      "image:  879\n",
      "image:  880\n",
      "image:  881\n",
      "image:  882\n",
      "image:  883\n",
      "image:  884\n",
      "image:  885\n",
      "image:  886\n",
      "image:  887\n",
      "class name:  healthy\n",
      "image:  888\n",
      "image:  889\n",
      "image:  890\n",
      "image:  891\n",
      "image:  892\n",
      "image:  893\n",
      "image:  894\n",
      "image:  895\n",
      "image:  896\n",
      "image:  897\n",
      "image:  898\n",
      "image:  899\n",
      "image:  900\n",
      "image:  901\n",
      "image:  902\n",
      "image:  903\n",
      "image:  904\n",
      "image:  905\n",
      "image:  906\n",
      "image:  907\n",
      "image:  908\n",
      "image:  909\n",
      "image:  910\n",
      "image:  911\n",
      "image:  912\n",
      "image:  913\n",
      "image:  914\n",
      "image:  915\n",
      "image:  916\n",
      "image:  917\n",
      "image:  918\n",
      "image:  919\n",
      "image:  920\n",
      "image:  921\n",
      "image:  922\n",
      "image:  923\n",
      "image:  924\n",
      "image:  925\n",
      "image:  926\n",
      "image:  927\n",
      "image:  928\n",
      "image:  929\n",
      "image:  930\n",
      "image:  931\n",
      "image:  932\n",
      "image:  933\n",
      "image:  934\n",
      "image:  935\n",
      "image:  936\n",
      "image:  937\n",
      "image:  938\n",
      "image:  939\n",
      "image:  940\n",
      "image:  941\n",
      "image:  942\n",
      "image:  943\n",
      "image:  944\n",
      "image:  945\n",
      "image:  946\n",
      "image:  947\n",
      "image:  948\n",
      "image:  949\n",
      "image:  950\n",
      "image:  951\n",
      "image:  952\n",
      "image:  953\n",
      "image:  954\n",
      "image:  955\n",
      "image:  956\n",
      "image:  957\n",
      "image:  958\n",
      "image:  959\n",
      "image:  960\n",
      "image:  961\n",
      "image:  962\n",
      "image:  963\n",
      "image:  964\n",
      "image:  965\n",
      "image:  966\n",
      "image:  967\n",
      "image:  968\n",
      "image:  969\n",
      "image:  970\n",
      "image:  971\n",
      "image:  972\n",
      "image:  973\n",
      "image:  974\n",
      "image:  975\n",
      "image:  976\n",
      "image:  977\n",
      "image:  978\n",
      "image:  979\n",
      "image:  980\n",
      "image:  981\n",
      "image:  982\n",
      "image:  983\n",
      "image:  984\n",
      "image:  985\n",
      "image:  986\n",
      "image:  987\n",
      "image:  988\n",
      "image:  989\n",
      "image:  990\n",
      "image:  991\n",
      "image:  992\n",
      "image:  993\n",
      "image:  994\n",
      "image:  995\n",
      "image:  996\n",
      "image:  997\n",
      "image:  998\n",
      "image:  999\n",
      "image:  1000\n",
      "image:  1001\n",
      "image:  1002\n",
      "image:  1003\n",
      "image:  1004\n",
      "image:  1005\n",
      "image:  1006\n",
      "image:  1007\n",
      "image:  1008\n",
      "image:  1009\n",
      "image:  1010\n",
      "image:  1011\n",
      "image:  1012\n",
      "image:  1013\n",
      "image:  1014\n",
      "image:  1015\n",
      "image:  1016\n",
      "image:  1017\n",
      "image:  1018\n",
      "image:  1019\n",
      "image:  1020\n",
      "image:  1021\n",
      "image:  1022\n",
      "image:  1023\n",
      "image:  1024\n",
      "image:  1025\n",
      "image:  1026\n",
      "image:  1027\n",
      "image:  1028\n",
      "image:  1029\n",
      "image:  1030\n",
      "image:  1031\n",
      "image:  1032\n",
      "image:  1033\n",
      "image:  1034\n",
      "image:  1035\n",
      "image:  1036\n",
      "image:  1037\n",
      "image:  1038\n",
      "image:  1039\n",
      "image:  1040\n",
      "image:  1041\n",
      "image:  1042\n",
      "image:  1043\n",
      "image:  1044\n",
      "image:  1045\n",
      "image:  1046\n",
      "image:  1047\n",
      "image:  1048\n",
      "image:  1049\n",
      "image:  1050\n",
      "image:  1051\n",
      "image:  1052\n",
      "image:  1053\n",
      "image:  1054\n",
      "image:  1055\n",
      "image:  1056\n",
      "image:  1057\n",
      "image:  1058\n",
      "image:  1059\n",
      "image:  1060\n",
      "image:  1061\n",
      "image:  1062\n",
      "image:  1063\n",
      "image:  1064\n",
      "image:  1065\n",
      "image:  1066\n",
      "image:  1067\n",
      "image:  1068\n",
      "image:  1069\n",
      "image:  1070\n",
      "image:  1071\n",
      "image:  1072\n",
      "image:  1073\n",
      "image:  1074\n",
      "image:  1075\n",
      "image:  1076\n",
      "image:  1077\n",
      "image:  1078\n",
      "image:  1079\n",
      "image:  1080\n",
      "image:  1081\n",
      "image:  1082\n",
      "image:  1083\n",
      "image:  1084\n",
      "image:  1085\n",
      "image:  1086\n",
      "image:  1087\n",
      "image:  1088\n",
      "image:  1089\n",
      "image:  1090\n",
      "image:  1091\n",
      "image:  1092\n",
      "image:  1093\n",
      "image:  1094\n",
      "image:  1095\n",
      "image:  1096\n",
      "image:  1097\n",
      "image:  1098\n",
      "image:  1099\n",
      "image:  1100\n",
      "image:  1101\n",
      "image:  1102\n",
      "image:  1103\n",
      "image:  1104\n",
      "image:  1105\n",
      "image:  1106\n",
      "image:  1107\n",
      "image:  1108\n",
      "image:  1109\n",
      "image:  1110\n",
      "image:  1111\n",
      "image:  1112\n",
      "image:  1113\n",
      "image:  1114\n",
      "image:  1115\n",
      "image:  1116\n",
      "image:  1117\n",
      "image:  1118\n",
      "image:  1119\n",
      "image:  1120\n",
      "image:  1121\n",
      "image:  1122\n",
      "image:  1123\n",
      "image:  1124\n",
      "image:  1125\n",
      "image:  1126\n",
      "image:  1127\n",
      "image:  1128\n",
      "image:  1129\n",
      "image:  1130\n",
      "image:  1131\n",
      "image:  1132\n",
      "image:  1133\n",
      "image:  1134\n",
      "image:  1135\n",
      "image:  1136\n",
      "image:  1137\n",
      "image:  1138\n",
      "image:  1139\n",
      "image:  1140\n",
      "image:  1141\n",
      "image:  1142\n",
      "image:  1143\n",
      "image:  1144\n",
      "image:  1145\n",
      "image:  1146\n",
      "image:  1147\n",
      "image:  1148\n",
      "image:  1149\n",
      "image:  1150\n",
      "image:  1151\n",
      "image:  1152\n",
      "image:  1153\n",
      "image:  1154\n",
      "image:  1155\n",
      "image:  1156\n",
      "image:  1157\n",
      "image:  1158\n",
      "image:  1159\n",
      "image:  1160\n",
      "image:  1161\n",
      "image:  1162\n",
      "image:  1163\n",
      "image:  1164\n",
      "image:  1165\n",
      "image:  1166\n",
      "image:  1167\n",
      "image:  1168\n",
      "image:  1169\n",
      "image:  1170\n",
      "image:  1171\n",
      "image:  1172\n",
      "image:  1173\n",
      "image:  1174\n",
      "image:  1175\n",
      "image:  1176\n",
      "image:  1177\n",
      "image:  1178\n",
      "image:  1179\n",
      "image:  1180\n",
      "image:  1181\n",
      "image:  1182\n",
      "image:  1183\n",
      "image:  1184\n",
      "image:  1185\n",
      "image:  1186\n",
      "image:  1187\n",
      "image:  1188\n",
      "image:  1189\n",
      "image:  1190\n",
      "image:  1191\n",
      "image:  1192\n",
      "image:  1193\n",
      "image:  1194\n",
      "image:  1195\n",
      "image:  1196\n",
      "image:  1197\n",
      "image:  1198\n",
      "image:  1199\n",
      "image:  1200\n",
      "image:  1201\n",
      "image:  1202\n",
      "image:  1203\n",
      "image:  1204\n",
      "image:  1205\n",
      "image:  1206\n",
      "image:  1207\n",
      "image:  1208\n",
      "image:  1209\n",
      "image:  1210\n",
      "image:  1211\n",
      "image:  1212\n",
      "image:  1213\n",
      "image:  1214\n",
      "image:  1215\n",
      "image:  1216\n",
      "image:  1217\n",
      "image:  1218\n",
      "image:  1219\n",
      "image:  1220\n",
      "image:  1221\n",
      "image:  1222\n",
      "image:  1223\n",
      "image:  1224\n",
      "image:  1225\n",
      "image:  1226\n",
      "image:  1227\n",
      "image:  1228\n",
      "image:  1229\n",
      "image:  1230\n",
      "image:  1231\n",
      "image:  1232\n",
      "image:  1233\n",
      "image:  1234\n",
      "image:  1235\n",
      "image:  1236\n",
      "image:  1237\n",
      "image:  1238\n",
      "image:  1239\n",
      "image:  1240\n",
      "image:  1241\n",
      "image:  1242\n",
      "image:  1243\n",
      "image:  1244\n",
      "image:  1245\n",
      "image:  1246\n",
      "image:  1247\n",
      "image:  1248\n",
      "image:  1249\n",
      "image:  1250\n",
      "image:  1251\n",
      "image:  1252\n",
      "image:  1253\n",
      "image:  1254\n",
      "image:  1255\n",
      "image:  1256\n",
      "image:  1257\n",
      "image:  1258\n",
      "image:  1259\n",
      "image:  1260\n",
      "image:  1261\n",
      "image:  1262\n",
      "image:  1263\n",
      "image:  1264\n",
      "image:  1265\n",
      "image:  1266\n",
      "image:  1267\n",
      "image:  1268\n",
      "image:  1269\n",
      "image:  1270\n",
      "image:  1271\n",
      "image:  1272\n",
      "image:  1273\n",
      "image:  1274\n",
      "image:  1275\n",
      "image:  1276\n",
      "image:  1277\n",
      "image:  1278\n",
      "image:  1279\n",
      "image:  1280\n",
      "image:  1281\n",
      "image:  1282\n",
      "image:  1283\n",
      "image:  1284\n",
      "image:  1285\n",
      "image:  1286\n",
      "image:  1287\n",
      "image:  1288\n",
      "image:  1289\n",
      "image:  1290\n",
      "image:  1291\n",
      "image:  1292\n",
      "image:  1293\n",
      "image:  1294\n",
      "image:  1295\n",
      "image:  1296\n",
      "image:  1297\n",
      "image:  1298\n",
      "image:  1299\n",
      "image:  1300\n",
      "image:  1301\n",
      "image:  1302\n",
      "image:  1303\n",
      "image:  1304\n",
      "image:  1305\n",
      "image:  1306\n",
      "image:  1307\n",
      "image:  1308\n",
      "image:  1309\n",
      "image:  1310\n",
      "image:  1311\n",
      "image:  1312\n",
      "image:  1313\n",
      "image:  1314\n",
      "image:  1315\n",
      "image:  1316\n",
      "image:  1317\n",
      "image:  1318\n",
      "image:  1319\n",
      "image:  1320\n",
      "image:  1321\n",
      "image:  1322\n",
      "image:  1323\n",
      "image:  1324\n",
      "image:  1325\n",
      "image:  1326\n",
      "image:  1327\n",
      "image:  1328\n",
      "image:  1329\n",
      "image:  1330\n",
      "image:  1331\n",
      "image:  1332\n",
      "image:  1333\n",
      "image:  1334\n",
      "image:  1335\n",
      "image:  1336\n",
      "image:  1337\n",
      "image:  1338\n",
      "image:  1339\n",
      "image:  1340\n",
      "image:  1341\n",
      "image:  1342\n",
      "image:  1343\n",
      "image:  1344\n",
      "image:  1345\n",
      "image:  1346\n",
      "image:  1347\n",
      "image:  1348\n",
      "image:  1349\n",
      "image:  1350\n",
      "image:  1351\n",
      "image:  1352\n",
      "image:  1353\n",
      "image:  1354\n",
      "image:  1355\n",
      "image:  1356\n",
      "image:  1357\n",
      "image:  1358\n",
      "image:  1359\n",
      "image:  1360\n",
      "image:  1361\n",
      "image:  1362\n",
      "image:  1363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image:  1364\n",
      "image:  1365\n",
      "image:  1366\n",
      "image:  1367\n",
      "image:  1368\n",
      "image:  1369\n",
      "image:  1370\n",
      "image:  1371\n",
      "image:  1372\n",
      "image:  1373\n",
      "image:  1374\n",
      "image:  1375\n",
      "image:  1376\n",
      "image:  1377\n",
      "image:  1378\n",
      "image:  1379\n",
      "image:  1380\n",
      "image:  1381\n",
      "image:  1382\n",
      "image:  1383\n",
      "image:  1384\n",
      "image:  1385\n",
      "image:  1386\n",
      "image:  1387\n",
      "image:  1388\n",
      "image:  1389\n",
      "image:  1390\n",
      "image:  1391\n",
      "image:  1392\n",
      "image:  1393\n",
      "image:  1394\n",
      "image:  1395\n",
      "image:  1396\n",
      "image:  1397\n",
      "image:  1398\n",
      "image:  1399\n",
      "image:  1400\n",
      "image:  1401\n",
      "image:  1402\n",
      "image:  1403\n",
      "image:  1404\n",
      "image:  1405\n",
      "image:  1406\n",
      "image:  1407\n",
      "image:  1408\n",
      "image:  1409\n",
      "image:  1410\n",
      "image:  1411\n",
      "image:  1412\n",
      "image:  1413\n",
      "image:  1414\n",
      "image:  1415\n",
      "image:  1416\n",
      "image:  1417\n",
      "updating k:  0\n",
      "3\n",
      "image:  1418\n",
      "image:  1419\n",
      "image:  1420\n",
      "image:  1421\n",
      "image:  1422\n",
      "image:  1423\n",
      "image:  1424\n",
      "image:  1425\n",
      "image:  1426\n",
      "image:  1427\n",
      "image:  1428\n",
      "image:  1429\n",
      "image:  1430\n",
      "image:  1431\n",
      "image:  1432\n",
      "image:  1433\n",
      "image:  1434\n",
      "image:  1435\n",
      "image:  1436\n",
      "image:  1437\n",
      "image:  1438\n",
      "image:  1439\n",
      "image:  1440\n",
      "image:  1441\n",
      "image:  1442\n",
      "image:  1443\n",
      "image:  1444\n",
      "image:  1445\n",
      "image:  1446\n",
      "image:  1447\n",
      "image:  1448\n",
      "image:  1449\n",
      "image:  1450\n",
      "image:  1451\n",
      "image:  1452\n",
      "image:  1453\n",
      "image:  1454\n",
      "image:  1455\n",
      "image:  1456\n",
      "image:  1457\n",
      "image:  1458\n",
      "image:  1459\n",
      "image:  1460\n",
      "image:  1461\n",
      "image:  1462\n",
      "image:  1463\n",
      "image:  1464\n",
      "image:  1465\n",
      "image:  1466\n",
      "image:  1467\n",
      "image:  1468\n",
      "image:  1469\n",
      "image:  1470\n",
      "image:  1471\n",
      "image:  1472\n",
      "image:  1473\n",
      "image:  1474\n",
      "image:  1475\n",
      "image:  1476\n",
      "image:  1477\n",
      "image:  1478\n",
      "image:  1479\n",
      "image:  1480\n",
      "image:  1481\n",
      "image:  1482\n",
      "image:  1483\n",
      "image:  1484\n",
      "image:  1485\n",
      "image:  1486\n",
      "image:  1487\n",
      "image:  1488\n",
      "image:  1489\n",
      "image:  1490\n",
      "image:  1491\n",
      "image:  1492\n",
      "image:  1493\n",
      "image:  1494\n",
      "image:  1495\n",
      "image:  1496\n",
      "image:  1497\n",
      "image:  1498\n",
      "image:  1499\n",
      "image:  1500\n",
      "image:  1501\n",
      "image:  1502\n",
      "image:  1503\n",
      "image:  1504\n",
      "image:  1505\n",
      "image:  1506\n",
      "image:  1507\n",
      "image:  1508\n",
      "image:  1509\n",
      "image:  1510\n",
      "image:  1511\n",
      "image:  1512\n",
      "image:  1513\n",
      "image:  1514\n",
      "image:  1515\n",
      "image:  1516\n",
      "image:  1517\n",
      "image:  1518\n",
      "image:  1519\n",
      "image:  1520\n",
      "image:  1521\n",
      "image:  1522\n",
      "image:  1523\n",
      "image:  1524\n",
      "image:  1525\n",
      "image:  1526\n",
      "image:  1527\n",
      "image:  1528\n",
      "image:  1529\n",
      "image:  1530\n",
      "image:  1531\n",
      "image:  1532\n",
      "image:  1533\n",
      "image:  1534\n",
      "image:  1535\n",
      "image:  1536\n",
      "image:  1537\n",
      "image:  1538\n",
      "image:  1539\n",
      "image:  1540\n",
      "image:  1541\n",
      "image:  1542\n",
      "image:  1543\n",
      "image:  1544\n",
      "image:  1545\n",
      "image:  1546\n",
      "image:  1547\n",
      "image:  1548\n",
      "image:  1549\n",
      "updating k:  1\n",
      "3\n",
      "image:  1550\n",
      "image:  1551\n",
      "image:  1552\n",
      "image:  1553\n",
      "image:  1554\n",
      "image:  1555\n",
      "image:  1556\n",
      "image:  1557\n",
      "image:  1558\n",
      "image:  1559\n",
      "image:  1560\n",
      "image:  1561\n",
      "image:  1562\n",
      "image:  1563\n",
      "image:  1564\n",
      "image:  1565\n",
      "image:  1566\n",
      "image:  1567\n",
      "image:  1568\n",
      "image:  1569\n",
      "image:  1570\n",
      "image:  1571\n",
      "image:  1572\n",
      "image:  1573\n",
      "image:  1574\n",
      "image:  1575\n",
      "image:  1576\n",
      "image:  1577\n",
      "image:  1578\n",
      "image:  1579\n",
      "image:  1580\n",
      "image:  1581\n",
      "image:  1582\n",
      "image:  1583\n",
      "image:  1584\n",
      "image:  1585\n",
      "image:  1586\n",
      "image:  1587\n",
      "image:  1588\n",
      "image:  1589\n",
      "image:  1590\n",
      "image:  1591\n",
      "image:  1592\n",
      "image:  1593\n",
      "image:  1594\n",
      "image:  1595\n",
      "image:  1596\n",
      "image:  1597\n",
      "image:  1598\n",
      "image:  1599\n",
      "image:  1600\n",
      "image:  1601\n",
      "image:  1602\n",
      "image:  1603\n",
      "image:  1604\n",
      "image:  1605\n",
      "image:  1606\n",
      "image:  1607\n",
      "image:  1608\n",
      "image:  1609\n",
      "image:  1610\n",
      "image:  1611\n",
      "image:  1612\n",
      "image:  1613\n",
      "image:  1614\n",
      "image:  1615\n",
      "image:  1616\n",
      "image:  1617\n",
      "image:  1618\n",
      "image:  1619\n",
      "image:  1620\n",
      "image:  1621\n",
      "image:  1622\n",
      "image:  1623\n",
      "image:  1624\n",
      "image:  1625\n",
      "image:  1626\n",
      "image:  1627\n",
      "image:  1628\n",
      "image:  1629\n",
      "image:  1630\n",
      "image:  1631\n",
      "image:  1632\n",
      "image:  1633\n",
      "image:  1634\n",
      "image:  1635\n",
      "image:  1636\n",
      "image:  1637\n",
      "image:  1638\n",
      "image:  1639\n",
      "image:  1640\n",
      "image:  1641\n",
      "image:  1642\n",
      "image:  1643\n",
      "image:  1644\n",
      "image:  1645\n",
      "image:  1646\n",
      "image:  1647\n",
      "image:  1648\n",
      "image:  1649\n",
      "image:  1650\n",
      "image:  1651\n",
      "image:  1652\n",
      "image:  1653\n",
      "image:  1654\n",
      "image:  1655\n",
      "image:  1656\n",
      "image:  1657\n",
      "image:  1658\n",
      "image:  1659\n",
      "image:  1660\n",
      "image:  1661\n",
      "image:  1662\n",
      "image:  1663\n",
      "image:  1664\n",
      "image:  1665\n",
      "image:  1666\n",
      "image:  1667\n",
      "image:  1668\n",
      "image:  1669\n",
      "image:  1670\n",
      "image:  1671\n",
      "image:  1672\n",
      "image:  1673\n",
      "image:  1674\n",
      "image:  1675\n",
      "image:  1676\n",
      "image:  1677\n",
      "image:  1678\n",
      "image:  1679\n",
      "image:  1680\n",
      "image:  1681\n",
      "image:  1682\n",
      "image:  1683\n",
      "image:  1684\n",
      "image:  1685\n",
      "image:  1686\n",
      "image:  1687\n",
      "image:  1688\n",
      "image:  1689\n",
      "image:  1690\n",
      "image:  1691\n",
      "image:  1692\n",
      "image:  1693\n",
      "image:  1694\n",
      "image:  1695\n",
      "image:  1696\n",
      "image:  1697\n",
      "image:  1698\n",
      "image:  1699\n",
      "image:  1700\n",
      "image:  1701\n",
      "image:  1702\n",
      "image:  1703\n",
      "image:  1704\n",
      "image:  1705\n",
      "image:  1706\n",
      "image:  1707\n",
      "image:  1708\n",
      "image:  1709\n",
      "image:  1710\n",
      "image:  1711\n",
      "image:  1712\n",
      "image:  1713\n",
      "image:  1714\n",
      "image:  1715\n",
      "image:  1716\n",
      "image:  1717\n",
      "image:  1718\n",
      "image:  1719\n",
      "image:  1720\n",
      "image:  1721\n",
      "image:  1722\n",
      "image:  1723\n",
      "image:  1724\n",
      "image:  1725\n",
      "image:  1726\n",
      "image:  1727\n",
      "image:  1728\n",
      "image:  1729\n",
      "image:  1730\n",
      "image:  1731\n",
      "image:  1732\n",
      "image:  1733\n",
      "image:  1734\n",
      "image:  1735\n",
      "image:  1736\n",
      "image:  1737\n",
      "image:  1738\n",
      "image:  1739\n",
      "image:  1740\n",
      "image:  1741\n",
      "image:  1742\n",
      "image:  1743\n",
      "image:  1744\n",
      "image:  1745\n",
      "image:  1746\n",
      "image:  1747\n",
      "image:  1748\n",
      "image:  1749\n",
      "image:  1750\n",
      "image:  1751\n",
      "image:  1752\n",
      "image:  1753\n",
      "image:  1754\n",
      "image:  1755\n",
      "image:  1756\n",
      "image:  1757\n",
      "image:  1758\n",
      "image:  1759\n",
      "image:  1760\n",
      "image:  1761\n",
      "image:  1762\n",
      "image:  1763\n",
      "image:  1764\n",
      "image:  1765\n",
      "image:  1766\n",
      "image:  1767\n",
      "image:  1768\n",
      "image:  1769\n"
     ]
    }
   ],
   "source": [
    "# SPLIT DATASET (and resize) *************************************\n",
    "print(\"Split dataset.....\")\n",
    "\n",
    "i=0\n",
    "j=0\n",
    "k=0\n",
    "for class_name in CLASS_NAMES: # \"j\" cambia con il tipo di pianta [0,3]\n",
    "\n",
    "    print(\"class name: \", class_name)\n",
    "\n",
    "    contatore_samples = 0\n",
    "    k=0\n",
    "\n",
    "    array = sorted(os.listdir(dir_original + '/' + class_name))\n",
    "    #random.shuffle(array)\n",
    "\n",
    "    for image_name in array: # \"contatore\" si azzera ad ogni campo 'train' 'validation' 'test'\n",
    "\n",
    "        print(\"image: \", i)\n",
    "        i=i+1\n",
    "        \n",
    "        if contatore_samples==N_samples[j][k] and k+1  < len(N_samples[j]):    # \"k\" cambia con train, validation, e test\n",
    "            print(\"updating k: \", k)\n",
    "            print(len(N_samples[j]))\n",
    "            k+=1\n",
    "            contatore_samples=0\n",
    "\n",
    "\n",
    "        img=Image.open(dir_original +'/'+class_name+'/'+image_name)\n",
    "        l,_ = img.size\n",
    "        l=int(l)\n",
    "        \n",
    "        \n",
    "        if l==1080 or l==720:\n",
    "        \n",
    "            transposed = img.transpose(Image.ROTATE_90)\n",
    "            transposed.thumbnail(size)\n",
    "            transposed.save(dir_processed+'/'+set_samples[k]+'/'+class_name+'/'+image_name)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            img.thumbnail(size)\n",
    "            img.save(dir_processed+'/'+set_samples[k]+'/'+class_name+'/'+image_name)\n",
    "\n",
    "        contatore_samples+=1\n",
    "\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ada4b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train root ./../data_processed\\train\n",
      "Directory './checkpoints_30_32_0001/' created\n"
     ]
    }
   ],
   "source": [
    "PATH_DATASET = './../data_processed'\n",
    " \n",
    "train_root_dir=os.path.join(PATH_DATASET, 'train')  \n",
    "val_root_dir= os.path.join(PATH_DATASET, 'validation')\n",
    "test_root_dir= os.path.join(PATH_DATASET, 'test') \n",
    "model_path=r'./checkpoints_30_32_0001/'  # set path to the folder that will store model's checkpoints\n",
    "\n",
    "n_classes=2  # number of classes used for training\n",
    "\n",
    "global val_f1_max\n",
    "\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(os.path.dirname(model_path)):\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "    \n",
    "print('train root', train_root_dir)\n",
    "\n",
    "print(\"Directory '% s' created\" % model_path)\n",
    "filename='results_e'+str(max_epochs)+'_'+'b'+str(batch_size)+'_'+'lr'+str(lr)+'_'+'resnet50'   #filename used for saving epoch-wise training details and test results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4886a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################\n",
    "# # Training\n",
    "# ####################################\n",
    "\n",
    "trans={\n",
    " # Train uses data augmentation\n",
    " 'train':\n",
    " transforms.Compose([\n",
    "     #transforms.Resize((224, 224)),\n",
    "     #transforms.RandomRotation(degrees=15),\n",
    "     #transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     #transforms.Normalize([0.4762, 0.3054, 0.2368], [0.3345, 0.2407, 0.2164])\n",
    "]),\n",
    " # Validation does not use augmentation\n",
    " 'valid':\n",
    " transforms.Compose([\n",
    "#          transforms.Resize((224,224)),\n",
    "     transforms.ToTensor(),\n",
    "#          transforms.Normalize([0.4762, 0.3054, 0.2368], [0.3345, 0.2407, 0.2164])\n",
    " ]),\n",
    "\n",
    " # Test does not use augmentation\n",
    " 'test':\n",
    " transforms.Compose([\n",
    "#          transforms.Resize((224,224)),\n",
    "     transforms.ToTensor(),\n",
    "#          transforms.Normalize([0.4762, 0.3054, 0.2368], [0.3345, 0.2407, 0.2164])\n",
    " ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cef8676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train:\n",
    "    def __init__(self):\n",
    "\n",
    "#         transform=trans['valid']\n",
    "        #Generators\n",
    "        training_dataset= datasets.ImageFolder(train_root_dir, transform=trans['train'])\n",
    "        validation_dataset= datasets.ImageFolder(val_root_dir, transform=trans['valid'])\n",
    "        test_dataset= datasets.ImageFolder(test_root_dir, transform=trans['test'])\n",
    "        \n",
    "        self.training_generator=data.DataLoader(training_dataset,batch_size,shuffle=True) # ** unpacks a dictionary into keyword arguments\n",
    "        self.validation_generator=data.DataLoader(validation_dataset,batch_size)\n",
    "        self.test_generator=data.DataLoader(test_dataset,batch_size)\n",
    "       \n",
    "        print('Number of Training set images:{}'.format(len(training_dataset)))\n",
    "        print('Number of Validation set images:{}'.format(len(validation_dataset)))\n",
    "        print('Number of Test set images:{}'.format(len(test_dataset)))\n",
    "        \n",
    "    def train_net(self):        \n",
    "                #Initialize model\n",
    "        model = torchvision.models.resnet50(weights=False).to(device)   # make weights=True if you want to download pre-trained weights   # make weights=True if you want to download pre-trained weights\n",
    "        \n",
    "        \n",
    "#         model.load_state_dict(torch.load('./densenet121.pth',map_location='cuda'))   # provide a .pth path for already downloaded weights; otherwise comment this line out\n",
    "        \n",
    "        \n",
    "        # Option to freeze model weights\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True                       # Set param.requires_grad = False if you want to train only the last updated layers and freeze all other layers\n",
    "        \n",
    "        n_inputs = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 256),\n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, n_classes),`   \n",
    "                      nn.LogSoftmax(dim=1))\n",
    "        \n",
    "       \n",
    "        model.to(device)\n",
    "        optimizer=optim.Adam(model.parameters(), lr, weight_decay=1e-4)\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=4,verbose=True)\n",
    "        criterion = nn.NLLLoss()\n",
    "        val_f1_max=0.0\n",
    "        epochs=[]\n",
    "        lossesT=[]\n",
    "        lossesV=[]\n",
    "\n",
    "        for epoch in range(max_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch+1,max_epochs))\n",
    "            print('-'*10)\n",
    "            \n",
    "            since=time.time()\n",
    "            train_metrics=defaultdict(float)\n",
    "            total_loss=0\n",
    "            running_corrects=0\n",
    "            num_steps=0\n",
    "            \n",
    "            all_labels_d = torch.tensor([], dtype=torch.long).to(device)\n",
    "            all_predictions_d = torch.tensor([], dtype=torch.long).to(device)\n",
    "            all_predictions_probabilities_d = torch.tensor([], dtype=torch.float).to(device)\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "            #Training\n",
    "            for image, labels in self.training_generator:\n",
    "                #Transfer to GPU:\n",
    "                \n",
    "                image, labels = image.to(device, dtype=torch.float32), labels.to(device)\n",
    "                outputs = model(image)\n",
    "                predicted_probability, predicted  = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "              \n",
    "                num_steps+=image.size(0)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss+=loss.item()*image.size(0)\n",
    "           \n",
    "                running_corrects += torch.sum(predicted == labels.data)\n",
    "                all_labels_d = torch.cat((all_labels_d, labels), 0)\n",
    "                all_predictions_d = torch.cat((all_predictions_d, predicted), 0)\n",
    "                all_predictions_probabilities_d = torch.cat((all_predictions_probabilities_d, predicted_probability), 0)\n",
    "                \n",
    "                \n",
    "            y_true = all_labels_d.cpu()\n",
    "            y_predicted = all_predictions_d.cpu()  # to('cpu')\n",
    "            valset_predicted_probabilites = all_predictions_probabilities_d.cpu()  # to('cpu')\n",
    "            \n",
    "            \n",
    "            #############################\n",
    "            # Standard metrics \n",
    "            #############################\n",
    "        \n",
    "            train_micro_precision=mtc.precision_score(y_true, y_predicted, average=\"micro\")     \n",
    "            train_micro_recall=mtc.recall_score(y_true, y_predicted, average=\"micro\")\n",
    "            train_micro_f1=mtc.f1_score(y_true, y_predicted, average=\"micro\")  \n",
    "        \n",
    "            train_macro_precision=mtc.precision_score(y_true, y_predicted, average=\"macro\")     \n",
    "            train_macro_recall=mtc.recall_score(y_true, y_predicted, average=\"macro\")\n",
    "            train_macro_f1=mtc.f1_score(y_true, y_predicted, average=\"macro\")  \n",
    "        \n",
    "            train_mcc=mtc.matthews_corrcoef(y_true, y_predicted)\n",
    "             \n",
    "            \n",
    "            train_metrics['loss']=total_loss/num_steps\n",
    "        \n",
    "            train_metrics['micro_precision']=train_micro_precision\n",
    "            train_metrics['micro_recall']=train_micro_recall\n",
    "            train_metrics['micro_f1']=train_micro_f1\n",
    "            train_metrics['macro_precision']=train_macro_precision\n",
    "            train_metrics['macro_recall']=train_macro_recall\n",
    "            train_metrics['macro_f1']=train_macro_f1\n",
    "            train_metrics['mcc']=train_mcc\n",
    "            \n",
    "            print('Training...')\n",
    "            print('Train_loss:{:.3f}'.format(total_loss/num_steps))\n",
    "           \n",
    "            \n",
    "            print_metrics(train_metrics,num_steps)\n",
    "\n",
    "            ############################\n",
    "            # Validation\n",
    "            ############################\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss, val_metrics, val_num_steps=validate_net(model,self.validation_generator,device,criterion)\n",
    "                \n",
    "            scheduler.step(val_loss)\n",
    "            epochs.append(epoch)\n",
    "            lossesT.append(total_loss/num_steps)\n",
    "            lossesV.append(val_loss)\n",
    "            \n",
    "            print('.'*5)\n",
    "            print('Validating...')\n",
    "            print('val_loss:{:.3f}'.format(val_loss))\n",
    "        \n",
    "            print_metrics(val_metrics,val_num_steps)\n",
    "\n",
    "\n",
    "            ##################################################################\n",
    "            # Writing epoch-wise training and validation results to a csv file \n",
    "            ##################################################################\n",
    "\n",
    "            key_name=['Epoch','Train_loss','Train_micro_precision','Train_micro_recall','Train_micro_f1','Train_macro_precision','Train_macro_recall','Train_macro_f1','Train_mcc','Val_loss','Val_micro_precision','Val_micro_recall','Val_micro_f1','Val_macro_precision','Val_macro_recall','Val_macro_f1','Val_mcc']\n",
    "            train_list=[]\n",
    "            train_list.append(epoch)\n",
    "\n",
    "            try:\n",
    "\n",
    "                with open(filename+str('.csv'), 'a',newline=\"\") as f:\n",
    "                    wr = csv.writer(f,delimiter=\",\")\n",
    "                    if epoch==0:\n",
    "                        wr.writerow(key_name)\n",
    "\n",
    "                    for k, vl in train_metrics.items():\n",
    "                        train_list.append(vl)\n",
    "\n",
    "                    train_list.append(val_loss)\n",
    "\n",
    "                    for k, vl in val_metrics.items():\n",
    "                        train_list.append(vl)\n",
    "                    zip(train_list)\n",
    "                    wr.writerow(train_list)\n",
    "\n",
    "\n",
    "            except IOError:\n",
    "                print(\"I/O Error\")\n",
    "\n",
    "            \n",
    "            ##############################\n",
    "            # Saving best model \n",
    "            ##############################\n",
    "            \n",
    "            if val_metrics['micro_f1']>=val_f1_max:\n",
    "                print('val micro f1 increased ({:.6f}-->{:.6f}).Saving model'.format(val_f1_max,val_metrics['micro_f1']))\n",
    "                \n",
    "                torch.save({'epoch':epoch+1,\n",
    "                            'model_state_dict':model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'scheduler': scheduler.state_dict(), \n",
    "                            'loss':val_loss},model_path+f'/C_{epoch+1}_{batch_size}.pth')\n",
    "                best_model_path=model_path+f'/C_{epoch+1}_{batch_size}.pth'\n",
    "               \n",
    "                val_f1_max=val_metrics['micro_f1']\n",
    "                \n",
    "\n",
    "            print('-'*10)\n",
    "       \n",
    "        time_elapsed=time.time()-since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        \n",
    "        training_curve(epochs,lossesT,lossesV)\n",
    "        epochs.clear()\n",
    "        lossesT.clear()\n",
    "        lossesV.clear()\n",
    "        \n",
    "\n",
    "        ############################\n",
    "        #         Test\n",
    "        ############################\n",
    "        test_list=[]\n",
    "        print('Best model path:{}'.format(best_model_path))\n",
    "        best_model=torchvision.models.resnet50(weights=False).to(device)\n",
    "        \n",
    "        n_inputs = best_model.fc.in_features\n",
    "        best_model.fc = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 256),\n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, n_classes),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    " \n",
    "        checkpoint=torch.load(best_model_path,map_location=device)   # loading best model\n",
    "        best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model.to(device)\n",
    "        best_model.eval()\n",
    "        with torch.no_grad():\n",
    "       \t       test_loss, test_metrics, test_num_steps=test_net(best_model,self.test_generator,device,criterion)\n",
    "\n",
    "        \n",
    "        print_metrics(test_metrics,test_num_steps)\n",
    "        test_list.append(test_loss)\n",
    "     \n",
    "\n",
    "        for k, vl in test_metrics.items():      \n",
    "            test_list.append(vl)              # append metrics results in a list\n",
    "  \n",
    "  \n",
    "  \n",
    "        ##################################################################\n",
    "        # Writing test results to a csv file \n",
    "        ##################################################################\n",
    "\n",
    "        key_name=['Test_loss','Test_micro_precision','Test_micro_recall','Test_micro_f1','Test_macro_precision','Test_macro_recall','Test_macro_f1','Test_mcc']\n",
    "        try:\n",
    "\n",
    "                with open(filename+str('.csv'), 'a',newline=\"\") as f:\n",
    "                    wr = csv.writer(f,delimiter=\",\")\n",
    "                    wr.writerow(key_name)\n",
    "                    zip(test_list)\n",
    "                    wr.writerow(test_list) \n",
    "                    wr.writerow(\"\") \n",
    "        except IOError:\n",
    "                print(\"I/O Error\")  \n",
    "        return val_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08524509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "435934c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device: cpu\n",
      "INFO: Starting training:\n",
      "             Epochs: 30\n",
      "             Batch Size: 32\n",
      "             Learning Rate: 0.0001\n",
      "C:\\Users\\User1\\anaconda3\\envs\\GrapevineDS\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\User1\\anaconda3\\envs\\GrapevineDS\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training set images:1062\n",
      "Number of Validation set images:265\n",
      "Number of Test set images:443\n",
      "Epoch 1/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.251\n",
      "loss:0.251441,micro_precision:0.876648,micro_recall:0.876648,micro_f1:0.876648,macro_precision:0.876920,macro_recall:0.876699,macro_f1:0.876635,mcc:0.753619\n",
      ".....\n",
      "Validating...\n",
      "val_loss:1.132\n",
      "micro_precision:0.773585,micro_recall:0.773585,micro_f1:0.773585,macro_precision:0.832758,macro_recall:0.774379,macro_f1:0.763393,mcc:0.604324\n",
      "val micro f1 increased (0.000000-->0.773585).Saving model\n",
      "----------\n",
      "Epoch 2/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.076\n",
      "loss:0.076433,micro_precision:0.972693,micro_recall:0.972693,micro_f1:0.972693,macro_precision:0.972697,macro_recall:0.972689,macro_f1:0.972692,mcc:0.945387\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.158\n",
      "micro_precision:0.943396,micro_recall:0.943396,micro_f1:0.943396,macro_precision:0.947557,macro_recall:0.943581,macro_f1:0.943280,mcc:0.891129\n",
      "val micro f1 increased (0.773585-->0.943396).Saving model\n",
      "----------\n",
      "Epoch 3/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.042\n",
      "loss:0.041512,micro_precision:0.983051,micro_recall:0.983051,micro_f1:0.983051,macro_precision:0.983051,macro_recall:0.983051,macro_f1:0.983051,mcc:0.966101\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.019\n",
      "micro_precision:0.988679,micro_recall:0.988679,micro_f1:0.988679,macro_precision:0.988721,macro_recall:0.988665,macro_f1:0.988679,mcc:0.977385\n",
      "val micro f1 increased (0.943396-->0.988679).Saving model\n",
      "----------\n",
      "Epoch 4/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.018\n",
      "loss:0.017680,micro_precision:0.992467,micro_recall:0.992467,micro_f1:0.992467,macro_precision:0.992467,macro_recall:0.992474,macro_f1:0.992467,mcc:0.984941\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.481\n",
      "micro_precision:0.800000,micro_recall:0.800000,micro_f1:0.800000,macro_precision:0.857527,macro_recall:0.799242,macro_f1:0.791335,mcc:0.654178\n",
      "----------\n",
      "Epoch 5/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.029\n",
      "loss:0.029117,micro_precision:0.989642,micro_recall:0.989642,micro_f1:0.989642,macro_precision:0.989640,macro_recall:0.989646,macro_f1:0.989642,mcc:0.979286\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.034\n",
      "micro_precision:0.984906,micro_recall:0.984906,micro_f1:0.984906,macro_precision:0.985401,macro_recall:0.984848,macro_f1:0.984900,mcc:0.970250\n",
      "----------\n",
      "Epoch 6/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.019\n",
      "loss:0.019459,micro_precision:0.994350,micro_recall:0.994350,micro_f1:0.994350,macro_precision:0.994350,macro_recall:0.994350,macro_f1:0.994350,mcc:0.988700\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.095\n",
      "micro_precision:0.966038,micro_recall:0.966038,micro_f1:0.966038,macro_precision:0.968085,macro_recall:0.966165,macro_f1:0.966007,mcc:0.934249\n",
      "----------\n",
      "Epoch 7/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.031\n",
      "loss:0.030980,micro_precision:0.989642,micro_recall:0.989642,micro_f1:0.989642,macro_precision:0.989647,macro_recall:0.989638,macro_f1:0.989642,mcc:0.979286\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.126\n",
      "micro_precision:0.973585,micro_recall:0.973585,micro_f1:0.973585,macro_precision:0.975000,macro_recall:0.973485,macro_f1:0.973561,mcc:0.948484\n",
      "----------\n",
      "Epoch 8/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.031\n",
      "loss:0.030827,micro_precision:0.992467,micro_recall:0.992467,micro_f1:0.992467,macro_precision:0.992467,macro_recall:0.992467,macro_f1:0.992467,mcc:0.984934\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.003\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (0.988679-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 9/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.033\n",
      "loss:0.033005,micro_precision:0.986817,micro_recall:0.986817,micro_f1:0.986817,macro_precision:0.986831,macro_recall:0.986831,macro_f1:0.986817,mcc:0.973663\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.011\n",
      "micro_precision:0.996226,micro_recall:0.996226,micro_f1:0.996226,macro_precision:0.996269,macro_recall:0.996212,macro_f1:0.996226,mcc:0.992481\n",
      "----------\n",
      "Epoch 10/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.021\n",
      "loss:0.020738,micro_precision:0.992467,micro_recall:0.992467,micro_f1:0.992467,macro_precision:0.992509,macro_recall:0.992453,macro_f1:0.992467,mcc:0.984961\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.004\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 11/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.014\n",
      "loss:0.014483,micro_precision:0.993409,micro_recall:0.993409,micro_f1:0.993409,macro_precision:0.993414,macro_recall:0.993405,macro_f1:0.993409,mcc:0.986819\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.009\n",
      "micro_precision:0.996226,micro_recall:0.996226,micro_f1:0.996226,macro_precision:0.996241,macro_recall:0.996241,macro_f1:0.996226,mcc:0.992481\n",
      "----------\n",
      "Epoch 12/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.005\n",
      "loss:0.005107,micro_precision:0.999058,micro_recall:0.999058,micro_f1:0.999058,macro_precision:0.999064,macro_recall:0.999055,macro_f1:0.999058,mcc:0.998118\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.000\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 13/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.009\n",
      "loss:0.008612,micro_precision:0.995292,micro_recall:0.995292,micro_f1:0.995292,macro_precision:0.995297,macro_recall:0.995288,macro_f1:0.995292,mcc:0.990585\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.008\n",
      "micro_precision:0.996226,micro_recall:0.996226,micro_f1:0.996226,macro_precision:0.996241,macro_recall:0.996241,macro_f1:0.996226,mcc:0.992481\n",
      "----------\n",
      "Epoch 14/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.028\n",
      "loss:0.027582,micro_precision:0.988701,micro_recall:0.988701,micro_f1:0.988701,macro_precision:0.988701,macro_recall:0.988707,macro_f1:0.988701,mcc:0.977408\n",
      ".....\n",
      "Validating...\n",
      "val_loss:1.998\n",
      "micro_precision:0.596226,micro_recall:0.596226,micro_f1:0.596226,macro_precision:0.777083,macro_recall:0.594697,macro_f1:0.515804,mcc:0.323969\n",
      "----------\n",
      "Epoch 15/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.045\n",
      "loss:0.044722,micro_precision:0.987759,micro_recall:0.987759,micro_f1:0.987759,macro_precision:0.987764,macro_recall:0.987769,macro_f1:0.987759,mcc:0.975534\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.026\n",
      "micro_precision:0.992453,micro_recall:0.992453,micro_f1:0.992453,macro_precision:0.992537,macro_recall:0.992481,macro_f1:0.992453,mcc:0.985019\n",
      "----------\n",
      "Epoch 16/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.070\n",
      "loss:0.069987,micro_precision:0.971751,micro_recall:0.971751,micro_f1:0.971751,macro_precision:0.971790,macro_recall:0.971737,macro_f1:0.971750,mcc:0.943527\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.071\n",
      "micro_precision:0.969811,micro_recall:0.969811,micro_f1:0.969811,macro_precision:0.971429,macro_recall:0.969925,macro_f1:0.969790,mcc:0.941352\n",
      "----------\n",
      "Epoch 17/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.013\n",
      "loss:0.012668,micro_precision:0.996234,micro_recall:0.996234,micro_f1:0.996234,macro_precision:0.996234,macro_recall:0.996241,macro_f1:0.996234,mcc:0.992474\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.001\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 18/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.007\n",
      "loss:0.006688,micro_precision:0.998117,micro_recall:0.998117,micro_f1:0.998117,macro_precision:0.998117,macro_recall:0.998117,macro_f1:0.998117,mcc:0.996233\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 19/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.007\n",
      "loss:0.006601,micro_precision:0.998117,micro_recall:0.998117,micro_f1:0.998117,macro_precision:0.998117,macro_recall:0.998117,macro_f1:0.998117,mcc:0.996233\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.003\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 20/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train_loss:0.010\n",
      "loss:0.009842,micro_precision:0.996234,micro_recall:0.996234,micro_f1:0.996234,macro_precision:0.996234,macro_recall:0.996241,macro_f1:0.996234,mcc:0.992474\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.003\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 21/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.006\n",
      "loss:0.005542,micro_precision:0.998117,micro_recall:0.998117,micro_f1:0.998117,macro_precision:0.998117,macro_recall:0.998117,macro_f1:0.998117,mcc:0.996233\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 22/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.003\n",
      "loss:0.002838,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 23/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.005\n",
      "loss:0.004677,micro_precision:0.998117,micro_recall:0.998117,micro_f1:0.998117,macro_precision:0.998117,macro_recall:0.998124,macro_f1:0.998117,mcc:0.996241\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 24/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.003\n",
      "loss:0.003336,micro_precision:0.999058,micro_recall:0.999058,micro_f1:0.999058,macro_precision:0.999064,macro_recall:0.999055,macro_f1:0.999058,mcc:0.998118\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.001\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 25/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.004\n",
      "loss:0.004431,micro_precision:0.999058,micro_recall:0.999058,micro_f1:0.999058,macro_precision:0.999064,macro_recall:0.999055,macro_f1:0.999058,mcc:0.998118\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.001\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 26/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.003\n",
      "loss:0.002504,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 27/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.007\n",
      "loss:0.006713,micro_precision:0.998117,micro_recall:0.998117,micro_f1:0.998117,macro_precision:0.998117,macro_recall:0.998124,macro_f1:0.998117,mcc:0.996241\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.001\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 28/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.003\n",
      "loss:0.002500,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 29/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.005\n",
      "loss:0.005304,micro_precision:0.998117,micro_recall:0.998117,micro_f1:0.998117,macro_precision:0.998117,macro_recall:0.998117,macro_f1:0.998117,mcc:0.996233\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.001\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "Epoch 30/30\n",
      "----------\n",
      "Training...\n",
      "Train_loss:0.002\n",
      "loss:0.001514,micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      ".....\n",
      "Validating...\n",
      "val_loss:0.002\n",
      "micro_precision:1.000000,micro_recall:1.000000,micro_f1:1.000000,macro_precision:1.000000,macro_recall:1.000000,macro_f1:1.000000,mcc:1.000000\n",
      "val micro f1 increased (1.000000-->1.000000).Saving model\n",
      "----------\n",
      "146m 57s\n",
      "Best model path:./checkpoints_30_32_0001//C_30_32.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\anaconda3\\envs\\GrapevineDS\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 443 test images: 98.645599 %\n",
      "[[216   6]\n",
      " [  0 221]]\n",
      "taking class names to plot CM\n",
      "Generating confution matrix\n",
      "Confusion matrix, without normalization\n",
      "[[216   6]\n",
      " [  0 221]]\n",
      "Finished confusion matrix drawing...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        esca       1.00      0.97      0.99       222\n",
      "     healthy       0.97      1.00      0.99       221\n",
      "\n",
      "    accuracy                           0.99       443\n",
      "   macro avg       0.99      0.99      0.99       443\n",
      "weighted avg       0.99      0.99      0.99       443\n",
      "\n",
      "micro_precision:0.986456,micro_recall:0.986456,micro_f1:0.986456,macro_precision:0.986784,macro_recall:0.986486,macro_f1:0.986454,mcc:0.973271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(float,\n",
       "             {'micro_precision': 1.0,\n",
       "              'micro_recall': 1.0,\n",
       "              'micro_f1': 1.0,\n",
       "              'macro_precision': 1.0,\n",
       "              'macro_recall': 1.0,\n",
       "              'macro_f1': 1.0,\n",
       "              'mcc': 1.0}),\n",
       " defaultdict(float,\n",
       "             {'micro_precision': 0.9864559819413092,\n",
       "              'micro_recall': 0.9864559819413092,\n",
       "              'micro_f1': 0.9864559819413092,\n",
       "              'macro_precision': 0.986784140969163,\n",
       "              'macro_recall': 0.9864864864864865,\n",
       "              'macro_f1': 0.9864542563600783,\n",
       "              'mcc': 0.9732705819399468}))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logging.info(f'Using device: {device}')\n",
    "logging.info(f'''Starting training:\n",
    "             Epochs: {max_epochs}\n",
    "             Batch Size: {batch_size}\n",
    "             Learning Rate: {lr}''')\n",
    "t=train()\n",
    "t.train_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e81f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484e664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047dd76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
